[
    {
        "id": 1,
        "questions": [
            "Which of the following AWS services are always free to use (Select two)?"
        ],
        "single_choice": false,
        "answers": [
            {
                "answer": "AWS Auto Scaling",
                "check": true
            },
            {
                "answer": "Amazon Elastic Compute Cloud (Amazon EC2)",
                "check": false
            },
            {
                "answer": "Amazon Simple Storage Service (Amazon S3)",
                "check": false
            },
            {
                "answer": "Amazon DynamoDB",
                "check": false
            },
            {
                "answer": "AWS Identity and Access Management (AWS IAM)",
                "check": true
            }
        ],
        "explanation": {
            "correct": "<strong>AWS Identity and Access Management (AWS IAM)</strong> - AWS Identity and Access Management (AWS IAM) enables you to manage access to AWS services and resources securely.\n Using IAM, you can create and manage AWS users and groups, and use permissions to allow and deny their access to AWS resources.\n IAM is a feature of your AWS account offered at no additional charge.\n<strong>AWS Auto Scaling</strong> - AWS Auto Scaling monitors your applications and automatically adjusts the capacity to maintain steady, predictable performance at the lowest possible cost.\n Using AWS Auto Scaling, it’s easy to setup application scaling for multiple resources across multiple services in minutes.\n AWS Auto Scaling is available at no additional charge.\n You pay only for the AWS resources needed to run your applications and Amazon CloudWatch monitoring fees.\n",
            "incorrect": "<strong>Amazon Elastic Compute Cloud (Amazon EC2)</strong> - Amazon Elastic Compute Cloud (Amazon EC2) is a web service that provides secure, resizable compute capacity in the cloud.\n It is designed to make web-scale cloud computing easier for developers.\n This is not a free service.\n You pay for what you use or depending on the plan you choose.\n<strong>Amazon Simple Storage Service (Amazon S3)</strong> - Amazon Simple Storage Service (Amazon S3) is an object storage service that offers industry-leading scalability, data availability, security, and performance.\n S3 service is not free and you pay to depend on the storage class you choose for your data.\n<strong>Amazon DynamoDB</strong> - Amazon DynamoDB is a key-value and document database that delivers single-digit millisecond performance at any scale.\n It's a fully managed, multi-Region, multi-master, durable database with built-in security, backup and restore, and in-memory caching for internet-scale applications.\n DynamoDB is not free and you are charged for reading, writing, and storing data in your DynamoDB tables, along with any optional features you choose to enable.\nReferences:",
            "reference": "https://aws.amazon.com/autoscaling/"
        }
    },
    {
        "id": 2,
        "questions": [
            "A startup runs its proprietary application on docker containers. As a Cloud Practitioner, which AWS service would you recommend so that the startup can run containers and still have access to the underlying servers?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "Amazon Elastic Container Registry (Amazon ECR)",
                "check": false
            },
            {
                "answer": "Amazon Elastic Container Service (Amazon ECS)",
                "check": true
            },
            {
                "answer": "AWS Fargate",
                "check": false
            },
            {
                "answer": "AWS Lambda",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>Amazon Elastic Container Service (Amazon ECS)</strong>Amazon Elastic Container Service (Amazon ECS) is a highly scalable, fast, container management service that makes it easy to run, stop, and manage Docker containers on a cluster.\n This is not a fully managed service and you can manage the underlying servers yourself.\n",
            "incorrect": "<strong>AWS Fargate</strong> - AWS Fargate is a serverless compute engine for containers.\n It works with both Amazon Elastic Container Service (Amazon ECS) and Amazon Elastic Kubernetes Service (Amazon EKS).\n AWS Fargate makes it easy for you to focus on building your applications.\n AWS Fargate removes the need to provision and manage servers, lets you specify and pay for resources per application, and improves security through application isolation by design.\n With AWS Fargate, you do not have access to the underlying servers, so this option is incorrect.\n<strong>AWS Lambda</strong> - AWS Lambda is a compute service that lets you run code without provisioning or managing servers.\n AWS Lambda executes your code only when needed and scales automatically, from a few requests per day to thousands per second.\n AWS Lambda does not support running container applications.\n<strong>Amazon Elastic Container Registry (Amazon ECR)</strong> - Amazon Elastic Container Registry (Amazon ECR) can be used to store, manage, and deploy Docker container images.\n Amazon Elastic Container Registry (Amazon ECR) eliminates the need to operate your container repositories.\n Amazon Elastic Container Registry (Amazon ECR) does not support running container applications.\nReference:",
            "reference": "https://aws.amazon.com/fargate/"
        }
    },
    {
        "id": 3,
        "questions": [
            "A silicon valley based healthcare startup stores anonymized patient health data on Amazon S3. The CTO further wants to ensure that any sensitive data on S3 is discovered and identified to prevent any sensitive data leaks. As a Cloud Practitioner, which AWS service would you recommend addressing this use-case?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "Amazon Polly",
                "check": false
            },
            {
                "answer": "Amazon Macie",
                "check": true
            },
            {
                "answer": "AWS Secrets Manager",
                "check": false
            },
            {
                "answer": "AWS Glue",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>Amazon Macie</strong>Amazon Macie is a fully managed data security and data privacy service that uses machine learning and pattern matching to discover and protect your sensitive data in AWS.\n Macie automatically provides an inventory of Amazon S3 buckets including a list of unencrypted buckets, publicly accessible buckets, and buckets shared with AWS accounts outside those you have defined in AWS Organizations.\n Then, Macie applies machine learning and pattern matching techniques to the buckets you select to identify and alert you to sensitive data, such as personally identifiable information (PII).\n",
            "incorrect": "<strong>AWS Glue</strong> - AWS Glue is a fully managed extract, transform, and load (ETL) service that makes it easy for customers to prepare and load their data for analytics.\n AWS Glue job is meant to be used for batch ETL data processing.\n It cannot be used to discover and protect your sensitive data in AWS.\n<strong>Amazon Polly</strong> - Amazon Polly is a service that turns text into lifelike speech, allowing you to create applications that talk, and build entirely new categories of speech-enabled products.\n Polly's Text-to-Speech (TTS) service uses advanced deep learning technologies to synthesize natural sounding human speech.\n It cannot be used to discover and protect your sensitive data in AWS.\n<strong>AWS Secrets Manager</strong> - AWS Secrets Manager helps you protect secrets needed to access your applications, services, and IT resources.\n The service enables you to easily rotate, manage, and retrieve database credentials, API keys, and other secrets throughout their lifecycle.\n Users and applications retrieve secrets with a call to Secrets Manager APIs, eliminating the need to hardcode sensitive information in plain text.\n It cannot be used to discover and protect your sensitive data in AWS.\nReference:",
            "reference": "https://aws.amazon.com/macie/"
        }
    },
    {
        "id": 4,
        "questions": [
            "Which AWS service will you use to provision the same AWS infrastructure across multiple AWS accounts and regions?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "AWS Systems Manager",
                "check": false
            },
            {
                "answer": "AWS OpsWorks",
                "check": false
            },
            {
                "answer": "AWS CloudFormation",
                "check": true
            },
            {
                "answer": "AWS CodeDeploy",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>AWS CloudFormation</strong>AWS CloudFormation allows you to use programming languages or a simple text file to model and provision, in an automated and secure manner, all the resources needed for your applications across all Regions and accounts.\n A stack is a collection of AWS resources that you can manage as a single unit.\n In other words, you can create, update, or delete a collection of resources by creating, updating, or deleting stacks.\nAWS CloudFormation StackSets extends the functionality of stacks by enabling you to create, update, or delete stacks across multiple accounts and regions with a single operation.\n Using an administrator account, you define and manage an AWS CloudFormation template, and use the template as the basis for provisioning stacks into selected target accounts across specified regions.\n",
            "incorrect": "<strong>AWS CodeDeploy</strong> - AWS CodeDeploy is a fully managed deployment service that automates software deployments to a variety of compute services such as Amazon EC2, AWS Fargate, AWS Lambda, and your on-premises servers.\n AWS CodeDeploy makes it easier for you to rapidly release new features, helps you avoid downtime during application deployment, and handles the complexity of updating your applications.\n You cannot use this service to provision AWS infrastructure.\n<strong>AWS OpsWorks</strong> - AWS OpsWorks is a configuration management service that provides managed instances of Chef and Puppet.\n OpsWorks lets you use Chef and Puppet to automate how servers are configured, deployed and managed across your Amazon EC2 instances or on-premises compute environments.\n You cannot use OpsWorks for running commands or managing patches on servers.\n You cannot use this service to provision AWS infrastructure.\n<strong>AWS Systems Manager</strong> - AWS Systems Manager gives you visibility and control of your infrastructure on AWS.\n Systems Manager provides a unified user interface so you can view operational data from multiple AWS services and allows you to automate operational tasks across your AWS resources.\n With Systems Manager, you can group resources, like Amazon EC2 instances, Amazon S3 buckets, or Amazon RDS instances, by application, view operational data for monitoring and troubleshooting, and take action on your groups of resources.\n You cannot use this service to provision AWS infrastructure.\nReference:",
            "reference": "https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/what-is-cfnstacksets.html"
        }
    },
    {
        "id": 5,
        "questions": [
            "Which AWS service would you choose for a data processing project that needs a schemaless database?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "Amazon RedShift",
                "check": false
            },
            {
                "answer": "Amazon Relational Database Service (Amazon RDS)",
                "check": false
            },
            {
                "answer": "Amazon DynamoDB",
                "check": true
            },
            {
                "answer": "Amazon Aurora",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>Amazon DynamoDB</strong>Amazon DynamoDB is a key-value and document database that delivers single-digit millisecond performance at any scale.\n It's a fully managed, multi-Region, multi-master, durable database with built-in security, backup and restore, and in-memory caching for internet-scale applications.\n DynamoDB is schemaless.\n DynamoDB can manage structured or semistructured data, including JSON documents.\n",
            "incorrect": "<strong>Amazon RedShift</strong> - Amazon Redshift is a fully-managed petabyte-scale cloud-based data warehouse product designed for large scale data set storage and analysis.\n Amazon Redshift requires a well-defined schema.\n<strong>Amazon Aurora</strong> - Amazon Aurora is an AWS service for relational databases.\n Aurora requires a well-defined schema.\n<strong>Amazon Relational Database Service (Amazon RDS)</strong> - Amazon Relational Database Service (Amazon RDS) is an AWS service for relational databases.\n RDS requires a well-defined schema.\nReferences:",
            "reference": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SQLtoNoSQL.WhyDynamoDB.html"
        }
    },
    {
        "id": 6,
        "questions": [
            "Which pillar of the AWS Well-Architected Framework recommends maintaining infrastructure as code (IaC)?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "Performance Efficiency",
                "check": false
            },
            {
                "answer": "Security",
                "check": false
            },
            {
                "answer": "Operational Excellence",
                "check": true
            },
            {
                "answer": "Cost Optimization",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>Operational Excellence</strong>The AWS Well-Architected Framework helps you understand the pros and cons of decisions you make while building systems on AWS.\n By using the Framework you will learn architectural best practices for designing and operating reliable, secure, efficient, and cost-effective systems in the cloud.\n It provides a way for you to consistently measure your architectures against best practices and identify areas for improvement.\nThe AWS Well-Architected Framework is based on six pillars — Operational Excellence, Security, Reliability, Performance Efficiency, Cost Optimization and Sustainability.\nThe Operational Excellence pillar includes the ability to run and monitor systems to deliver business value and to continually improve supporting processes and procedures.\n In the cloud, you can apply the same engineering discipline that you use for application code to your entire environment.\n You can define your entire workload (applications, infrastructure) as code and update it with code.\n You can implement your operations procedures as code and automate their execution by triggering them in response to events.\n",
            "incorrect": "<strong>Cost Optimization</strong> - Cost Optimization focuses on avoiding un-needed costs.\n Key topics include understanding and controlling where the money is being spent, selecting the most appropriate and right number of resource types, analyzing spend over time, and scaling to meet business needs without overspending.\n<strong>Performance Efficiency</strong> - The performance efficiency pillar focuses on using IT and computing resources efficiently.\n Key topics include selecting the right resource types and sizes based on workload requirements, monitoring performance, and making informed decisions to maintain efficiency as business needs evolve.\n<strong>Security</strong> - The security pillar focuses on protecting information &amp; systems.\n Key topics include confidentiality and integrity of data, identifying and managing who can do what with privilege management, protecting systems, and establishing controls to detect security events.\nReference:",
            "reference": "https://wa.aws.amazon.com/wat.pillar.operationalExcellence.en.html"
        }
    },
    {
        "id": 7,
        "questions": [
            "Multi-AZ deployment is an example of which of the following?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "High Availability",
                "check": true
            },
            {
                "answer": "Scale up",
                "check": false
            },
            {
                "answer": "Performance Efficiency",
                "check": false
            },
            {
                "answer": "Scale out",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>High Availability</strong>A system that is available is capable of delivering the designed functionality at a given point in time.\n Highly available systems are those that can withstand some measure of degradation while still remaining available.\n On AWS Cloud, you can run instances for an application in a multi-AZ deployment to achieve High Availability.\n",
            "incorrect": "<strong>Scale out</strong> - The scale out (horizontal scaling) operation refers to an increase in capacity by adding more computers to the system.\n This is in contrast to a \"scale up\" operation, which is constrained to running its processes on only one computer; in such systems, the only way to increase performance is to add more resources into one computer in the form of faster (or more) CPUs, memory or storage.\n Horizontally scalable systems are oftentimes able to outperform vertically scalable systems by enabling parallel execution of workloads and distributing those across many different computers.\n Auto Scaling Group is an example of Horizontal Scaling on AWS.\n<strong>Scale up</strong> - The scale up (vertical scaling) operation implies adding more resources (like CPU, RAM) to a single node or machine.\n Example- Resizing an instance of EC2.\n<strong>Performance Efficiency</strong> - Performance Efficiency is the ability to use computing resources efficiently to meet system requirements and to maintain that efficiency as demand changes and technologies evolve.\nReferences:",
            "reference": "https://wa.aws.amazon.com/wat.concept.horizontal-scaling.en.html"
        }
    },
    {
        "id": 8,
        "questions": [
            "Which policy describes prohibited uses of the web services offered by Amazon Web Services?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "AWS Fair Use Policy",
                "check": false
            },
            {
                "answer": "AWS Acceptable Use Policy",
                "check": true
            },
            {
                "answer": "AWS Trusted Advisor",
                "check": false
            },
            {
                "answer": "AWS Applicable Use Policy",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>AWS Acceptable Use Policy</strong>",
            "incorrect": "<strong>AWS Trusted Advisor</strong> - AWS Trusted Advisor is an online tool that provides you real-time guidance to help you provision your resources following AWS best practices on cost optimization, security, fault tolerance, service limits, and performance improvement.\n Whether establishing new workflows, developing applications, or as part of ongoing improvement, recommendations provided by Trusted Advisor regularly help keep your solutions provisioned optimally.\n Trusted Advisor does not describe prohibited uses of the web services offered by Amazon Web Services.\n<strong>AWS Fair Use Policy</strong> - This is a made-up option and has been added as a distractor.\n<strong>AWS Applicable Use Policy</strong> - This is a made-up option and has been added as a distractor.\nReference:",
            "reference": "https://aws.amazon.com/aup/"
        }
    },
    {
        "id": 9,
        "questions": [
            "The DevOps team at an e-commerce company is trying to debug performance issues for its serverless application built using a microservices architecture. As a Cloud Practitioner, which AWS service would you recommend addressing this use-case?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "Amazon Pinpoint",
                "check": false
            },
            {
                "answer": "AWS Trusted Advisor",
                "check": false
            },
            {
                "answer": "AWS CloudFormation",
                "check": false
            },
            {
                "answer": "AWS X-Ray",
                "check": true
            }
        ],
        "explanation": {
            "correct": "<strong>AWS X-Ray</strong>You can use AWS X-Ray to analyze and debug serverless and distributed applications such as those built using a microservices architecture.\n With X-Ray, you can understand how your application and its underlying services are performing to identify and troubleshoot the root cause of performance issues and errors.\n",
            "incorrect": "<strong>AWS Trusted Advisor</strong> - AWS Trusted Advisor is an online tool that provides you real-time guidance to help you provision your resources following AWS best practices on cost optimization, security, fault tolerance, service limits and performance improvement.\n Whether establishing new workflows, developing applications, or as part of ongoing improvement, recommendations provided by Trusted Advisor regularly help keep your solutions provisioned optimally.\n Trusted Advisor cannot be used to debug performance issues for this serverless application built using a microservices architecture.\n<strong>Amazon Pinpoint</strong> - Amazon Pinpoint allows marketers and developers to deliver customer-centric engagement experiences by capturing customer usage data to draw real-time insights.\n Pinpoint cannot be used to debug performance issues for this serverless application built using a microservices architecture.\n<strong>AWS CloudFormation</strong> - AWS CloudFormation allows you to use programming languages or a simple text file to model and provision, in an automated and secure manner, all the resources needed for your applications across all Regions and accounts.\n Think infrastructure as code; think CloudFormation.\n CloudFormation cannot be used to debug performance issues for this serverless application built using a microservices architecture.\nReference:",
            "reference": "https://aws.amazon.com/xray/"
        }
    },
    {
        "id": 10,
        "questions": [
            "A photo sharing web application wants to store thumbnails of user-uploaded images on Amazon Simple Storage Service (Amazon S3). The thumbnails are rarely used but need to be immediately accessible from the web application. The thumbnails can be regenerated easily if they are lost. Which is the most cost-effective way to store these thumbnails on Amazon Simple Storage Service (Amazon S3)?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "Use Amazon S3 Standard to store the thumbnails",
                "check": false
            },
            {
                "answer": "Use Amazon S3 Standard-Infrequent Access (S3 Standard-IA) to store the thumbnails",
                "check": false
            },
            {
                "answer": "Use Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) to store the thumbnails",
                "check": true
            },
            {
                "answer": "Use Amazon S3 Glacier Flexible Retrieval to store the thumbnails",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>Use Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) to store the thumbnails</strong>Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) is for data that is accessed less frequently but requires rapid access when needed.\n Unlike other S3 Storage Classes which store data in a minimum of three Availability Zones (AZs), Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) stores data in a single Availability Zone (AZ) and costs 20% less than Amazon S3 Standard-Infrequent Access (S3 Standard-IA).\n Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) offers the same high durability, high throughput, and low latency of S3 Standard, with a low per GB storage price and per GB retrieval fee.\n Although Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) offers less availability than S3 Standard but that's not an issue for the given use-case since the thumbnails can be regenerated easily.\nAs the thumbnails are rarely used but need to be rapidly accessed when required, so Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) is the best choice for this use-case.\nExam Alert:",
            "incorrect": "<strong>Use Amazon S3 Standard-Infrequent Access (S3 Standard-IA) to store the thumbnails</strong> - Amazon S3 Standard-Infrequent Access (S3 Standard-IA) storage class is for data that is accessed less frequently but requires rapid access when needed.\n Amazon S3 Standard-Infrequent Access (S3 Standard-IA) matches the high durability, high throughput, and low latency of S3 Standard, with a low per GB storage price and per GB retrieval fee.\n Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) costs 20% less than Amazon S3 Standard-Infrequent Access (S3 Standard-IA), so this option is incorrect.\n<strong>Use Amazon S3 Standard to store the thumbnails</strong> - Amazon S3 Standard offers high durability, availability, and performance object storage for frequently accessed data.\n As described above, Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) is a better fit than Amazon S3 Standard, hence using Amazon S3 standard is ruled out for the given use-case.\n<strong>Use Amazon S3 Glacier Flexible Retrieval to store the thumbnails</strong> - Amazon S3 Glacier Flexible Retrieval is a secure, durable, and low-cost storage class for data archiving.\n Although Amazon S3 Glacier Flexible Retrieval is cheaper than Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA), however the retrieval time ranges from a minute to hours, so this option is also ruled out for the given use-case.\nReference:",
            "reference": "https://aws.amazon.com/s3/storage-classes/"
        }
    },
    {
        "id": 11,
        "questions": [
            "What is the primary benefit of deploying an Amazon Relational Database Service (Amazon RDS) database in a Read Replica configuration?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "Read Replica protects the database from a regional failure",
                "check": false
            },
            {
                "answer": "Read Replica reduces database usage costs",
                "check": false
            },
            {
                "answer": "Read Replica improves database scalability",
                "check": true
            },
            {
                "answer": "Read Replica enhances database availability",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>Read Replica improves database scalability</strong>Amazon Relational Database Service (Amazon RDS) makes it easy to set up, operate, and scale a relational database in the cloud.\n Read Replicas allow you to create read-only copies that are synchronized with your master database.\n Read Replicas are used for improved read performance.\n You can also place your read replica in a different AWS Region closer to your users for better performance.\n Read Replicas are an example of horizontal scaling of resources.\nExam Alert:",
            "incorrect": "<strong>Read Replica enhances database availability</strong> - Amazon RDS Multi-AZ deployments provide enhanced availability and durability for RDS database (DB) instances, making them a natural fit for production database workloads.\n When you provision a Multi-AZ DB Instance, Amazon RDS automatically creates a primary DB Instance and synchronously replicates the data to a standby instance in a different Availability Zone (AZ).\n Read Replica cannot enhance database availability.\n<strong>Read Replica protects the database from a regional failure</strong> - You need to use RDS in Multi-Region deployment configuration to protect from a regional failure.\n Read Replica cannot protect from a regional failure.\n<strong>Read Replica reduces database usage costs</strong> - Amazon Relational Database Service (Amazon RDS) with Read Replicas increases the database costs compared to the standard deployment.\n So this option is incorrect.\nReference:",
            "reference": "https://aws.amazon.com/rds/features/multi-az/"
        }
    },
    {
        "id": 12,
        "questions": [
            "Which benefit of Cloud Computing allows AWS to offer lower pay-as-you-go prices as usage from hundreds of thousands of customers is aggregated in the cloud?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "Massive economies of scale",
                "check": true
            },
            {
                "answer": "Trade capital expense for variable expense",
                "check": false
            },
            {
                "answer": "Go global in minutes",
                "check": false
            },
            {
                "answer": "Increased speed and agility",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>Massive economies of scale</strong>Cloud computing is the on-demand delivery of IT resources over the Internet with pay-as-you-go pricing.\n Instead of buying, owning, and maintaining physical data centers and servers, you can access technology services, such as computing power, storage, and databases, on an as-needed basis.\nBy using cloud computing, you can achieve a lower variable cost than you can get on your own.\n Because usage from hundreds of thousands of customers is aggregated in the cloud, providers such as AWS can achieve higher economies of scale, which translates into lower pay-as-you-go prices.\nExam Alert:",
            "incorrect": "<strong>Trade capital expense for variable expense</strong> - Instead of having to invest heavily in data centers and servers before you know how you’re going to use them, you can pay only when you consume computing resources, and pay only for how much you consume.\n<strong>Increased speed and agility</strong> - In a cloud computing environment, new IT resources are only a click away, which means that you reduce the time to make those resources available to your developers from weeks to just minutes.\n This results in a dramatic increase in agility for the organization since the cost and time it takes to experiment and develop is significantly lower.\n<strong>Go global in minutes</strong> - Easily deploy your application in multiple regions around the world with just a few clicks.\n This means you can provide lower latency and a better experience for your customers at minimal cost.\nAlthough these three options are also benefits of Cloud Computing, it is the massive economies of scale that allow AWS to offer lower pay-as-you-go prices as usage from hundreds of thousands of customers is aggregated in the cloud.\nReferences:",
            "reference": "https://docs.aws.amazon.com/whitepapers/latest/aws-overview/six-advantages-of-cloud-computing.html"
        }
    },
    {
        "id": 13,
        "questions": [
            "A developer would like to automate operations on his on-premises environment using Chef and Puppet. Which AWS service can help with this task?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "AWS Batch",
                "check": false
            },
            {
                "answer": "AWS CloudFormation",
                "check": false
            },
            {
                "answer": "AWS CodeDeploy",
                "check": false
            },
            {
                "answer": "AWS OpsWorks",
                "check": true
            }
        ],
        "explanation": {
            "correct": "<strong>AWS OpsWorks</strong>AWS OpsWorks is a configuration management service that provides managed instances of Chef and Puppet.\n Chef and Puppet are automation platforms that allow you to use code to automate the configurations of your servers.\n AWS OpsWorks lets you use Chef and Puppet to automate how servers are configured, deployed, and managed across your Amazon Elastic Compute Cloud (Amazon EC2) instances or on-premises compute environments.\n",
            "incorrect": "<strong>AWS CloudFormation</strong> - AWS CloudFormation gives developers and systems administrators an easy way to create and manage a collection of related AWS resources, provisioning and updating them in an orderly and predictable fashion.\n It does not use Chef and Puppet and is more focused on what and how AWS resources are procured.\n<strong>AWS CodeDeploy</strong> - AWS CodeDeploy is a service that automates code deployments to any instance, including Amazon Elastic Compute Cloud (Amazon EC2) instances and instances running on-premises.\n It does not use Chef and Puppet, and does not deal with infrastructure configuration and orchestration.\n<strong>AWS Batch</strong> - AWS Batch enables developers, scientists, and engineers to easily and efficiently run hundreds of thousands of batch computing jobs on AWS.\n It is not used to automate operations on his on-premises environment using Chef and Puppet.\nReference:",
            "reference": "https://aws.amazon.com/opsworks/"
        }
    },
    {
        "id": 14,
        "questions": [
            "A medical device company is looking for a durable and cost-effective way of storing their historic data. Due to compliance requirements, the data must be stored for 10 years. Which AWS Storage solution will you suggest?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "Amazon S3 Glacier Flexible Retrieval",
                "check": false
            },
            {
                "answer": "Amazon S3 Glacier Deep Archive",
                "check": true
            },
            {
                "answer": "Amazon Elastic File System (Amazon EFS)",
                "check": false
            },
            {
                "answer": "AWS Storage Gateway",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>Amazon S3 Glacier Deep Archive</strong>Amazon S3 Glacier Deep Archive is Amazon S3’s lowest-cost storage class and supports long-term retention and digital preservation for data that may be accessed once or twice in a year.\n It is designed for customers — particularly those in highly-regulated industries, such as the Financial Services, Healthcare, and Public Sectors — that retain data sets for 7-10 years or longer to meet regulatory compliance requirements.\n Amazon S3 Glacier Deep Archive can also be used for backup and disaster recovery use cases.\n It has a retrieval time (first byte latency) of 12 to 48 hours.\n",
            "incorrect": "<strong>Amazon S3 Glacier Flexible Retrieval</strong> - Amazon S3 Glacier Flexible Retrieval (formerly S3 Glacier) is the ideal storage class for archiving data that does not require immediate access but needs the flexibility to retrieve large sets of data at no cost, such as backup or disaster recovery use cases.\n Amazon S3 Glacier Deep Archive is a better fit as it is more cost-optimal than Amazon S3 Glacier Flexible Retrieval for the given use-case.\n<strong>AWS Storage Gateway</strong> - AWS Storage Gateway is a hybrid cloud storage service that gives you on-premises access to virtually unlimited cloud storage.\n All data transferred between the gateway and AWS storage is encrypted using SSL (for all three types of gateways - File, Volume and Tape Gateways).\n AWS Storage Gateway cannot be used for data archival.\n<strong>Amazon Elastic File System (Amazon EFS)</strong> - Amazon Elastic File System (Amazon EFS) provides a simple, scalable, fully managed elastic NFS file system for use with AWS Cloud services and on-premises resources.\n It is built to scale on-demand to petabytes without disrupting applications, growing and shrinking automatically as you add and remove files, eliminating the need to provision and manage capacity to accommodate growth.\nReference:",
            "reference": "https://aws.amazon.com/s3/storage-classes/"
        }
    },
    {
        "id": 15,
        "questions": [
            "Which of the following are the serverless computing services offered by AWS ? (Select two)"
        ],
        "single_choice": false,
        "answers": [
            {
                "answer": "AWS Elastic Beanstalk",
                "check": false
            },
            {
                "answer": "AWS Fargate",
                "check": true
            },
            {
                "answer": "AWS Lambda",
                "check": true
            },
            {
                "answer": "Amazon Lightsail",
                "check": false
            },
            {
                "answer": "Amazon Elastic Compute Cloud (Amazon EC2)",
                "check": false
            }
        ],
        "explanation": {
            "correct": "Serverless is the native architecture of the cloud that enables you to shift more of your operational responsibilities to AWS, increasing your agility and innovation.\n Serverless allows you to build and run applications and services without thinking about servers.\n It eliminates infrastructure management tasks such as server or cluster provisioning, patching, operating system maintenance, and capacity provisioning.\n<strong>AWS Lambda</strong>With AWS Lambda, you can run code for virtually any type of application or backend service - all with zero administration.\n Just upload your code and Lambda takes care of everything required to run and scale your code with high availability.\n You can set up your code to automatically trigger from other AWS services or call it directly from any web or mobile app.\nAWS Lambda lets you run code without provisioning or managing servers.\n You pay only for the compute time you consume - there is no charge when your code is not running.\n<strong>AWS Fargate</strong>AWS Fargate is a serverless compute engine for containers that works with both Amazon Elastic Container Service (ECS) and Amazon Elastic Kubernetes Service (EKS).\n Fargate makes it easy for you to focus on building your applications.\n Fargate removes the need to provision and manage servers, lets you specify and pay for resources per application, and improves security through application isolation by design.\nAWS Fargate is a purpose-built serverless compute engine for containers.\n Fargate scales and manages the infrastructure required to run your containers.\n",
            "incorrect": "<strong>Amazon Elastic Compute Cloud (Amazon EC2)</strong> - Amazon Elastic Compute Cloud (Amazon EC2) is a web service that provides secure, resizable compute capacity in the cloud with support for per-second billing.\n It is the easiest way to provision servers on AWS Cloud and access the underlying OS.\n Amazon EC2 reduces the time required to obtain and boot new server instances to minutes, allowing you to quickly scale capacity, both up and down, as your computing requirements change.\n<strong>AWS Elastic Beanstalk</strong> - AWS Elastic Beanstalk is an easy-to-use service for deploying and scaling web applications and services.\n You simply upload your code and Elastic Beanstalk automatically handles the deployment, from capacity provisioning, load balancing, auto-scaling to application health monitoring.\n Beanstalk provisions servers so it is not a serverless service.\n<strong>Amazon Lightsail</strong> - Amazon Lightsail is an easy-to-use cloud platform that offers you everything needed to build an application or website, plus a cost-effective, monthly plan.\n Lightsail offers several preconfigured, one-click-to-launch operating systems, development stacks, and web applications, including Linux, Windows OS, and WordPress.\nReferences:",
            "reference": "https://aws.amazon.com/fargate/"
        }
    },
    {
        "id": 16,
        "questions": [
            "An IT company is on a cost-optimization spree and wants to identify all Amazon Elastic Compute Cloud (Amazon EC2) instances that are under-utilized. Which AWS services can be used off-the-shelf to address this use-case without needing any manual configurations? (Select two)"
        ],
        "single_choice": false,
        "answers": [
            {
                "answer": "AWS Trusted Advisor",
                "check": true
            },
            {
                "answer": "AWS Cost Explorer",
                "check": true
            },
            {
                "answer": "AWS Cost & Usage Report (AWS CUR)",
                "check": false
            },
            {
                "answer": "AWS Budgets",
                "check": false
            },
            {
                "answer": "Amazon CloudWatch",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>AWS Trusted Advisor</strong>AWS Trusted Advisor is an online tool that provides real-time guidance to help provision your resources following AWS best practices.\n Whether establishing new workflows, developing applications, or as part of ongoing improvement, recommendations provided by Trusted Advisor regularly help keep your solutions provisioned optimally.\n AWS Trusted Advisor analyzes your AWS environment and provides best practice recommendations in five categories: Cost Optimization, Performance, Security, Fault Tolerance, Service Limits.\nAWS Trusted Advisor checks the Amazon Elastic Compute Cloud (Amazon EC2) instances that were running at any time during the last 14 days and alerts you if the daily CPU utilization was 10% or less and network I/O was 5 MB or less on 4 or more days.\n<strong>AWS Cost Explorer</strong>AWS Cost Explorer has an easy-to-use interface that lets you visualize, understand, and manage your AWS costs and usage over time.\n AWS Cost Explorer includes a default report that helps you visualize the costs and usage associated with your top five cost-accruing AWS services, and gives you a detailed breakdown of all services in the table view.\n The reports let you adjust the time range to view historical data going back up to twelve months to gain an understanding of your cost trends.\nThe rightsizing recommendations feature in AWS Cost Explorer helps you identify cost-saving opportunities by downsizing or terminating Amazon EC2 instances.\n You can see all of your underutilized Amazon EC2 instances across member accounts in a single view to immediately identify how much you can save.\n",
            "incorrect": "<strong>AWS Cost &amp; Usage Report (AWS CUR)</strong> - The AWS Cost &amp; Usage Report (AWS CUR) contains the most comprehensive set of cost and usage data available.\n You can use AWS Cost &amp; Usage Report (AWS CUR) to publish your AWS billing reports to an Amazon Simple Storage Service (Amazon S3) bucket that you own.\n You can receive reports that break down your costs by the hour or month, by product or product resource, or by tags that you define yourself.\n AWS Cost &amp; Usage Report (AWS CUR) cannot be used to identify under-utilized Amazon EC2 instances.\n<strong>Amazon CloudWatch</strong> - Amazon CloudWatch can be used to create alarm to monitor your estimated charges.\n When you enable the monitoring of estimated charges for your AWS account, the estimated charges are calculated and sent several times daily to CloudWatch as metric data.\n You can choose to receive alerts by email when charges have exceeded a certain threshold.\n Think resource performance monitoring, events, and alerts; think CloudWatch.\n Amazon CloudWatch cannot be used to identify under-utilized Amazon EC2 instances without manually configuring an alarm with the appropriate threshold to track the Amazon EC2 utilization, so this option is incorrect.\n<strong>AWS Budgets</strong> - AWS Budgets gives the ability to set custom budgets that alert you when your costs or usage exceed (or are forecasted to exceed) your budgeted amount.\n You can also use AWS Budgets to set reservation utilization or coverage targets and receive alerts when your utilization drops below the threshold you define.\n AWS Budgets can be created at the monthly, quarterly, or yearly level, and you can customize the start and end dates.\n You can further refine your budget to track costs associated with multiple dimensions, such as AWS service, linked account, tag, and others.\n AWS Budgets cannot be used to identify under-utilized EC2 instances without manually configuring coverage targets, so this option is incorrect.\nReferences:",
            "reference": "https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/ce-rightsizing.html"
        }
    },
    {
        "id": 17,
        "questions": [
            "Which of the following are the best practices when using AWS Organizations? (Select TWO)"
        ],
        "single_choice": false,
        "answers": [
            {
                "answer": "Do not use AWS Organizations to automate AWS account creation",
                "check": false
            },
            {
                "answer": "Never use tags for billing",
                "check": false
            },
            {
                "answer": "Create AWS accounts per department",
                "check": true
            },
            {
                "answer": "Disable AWS CloudTrail on several accounts",
                "check": false
            },
            {
                "answer": "Restrict account privileges using Service Control Policies (SCP)",
                "check": true
            }
        ],
        "explanation": {
            "correct": "<strong>Create AWS accounts per department</strong><strong>Restrict account privileges using Service Control Policies (SCP)</strong>AWS Organizations helps you centrally govern your environment as you grow and scale your workloads on AWS.\n Whether you are a growing startup or a large enterprise, AWS Organizations help you to centrally manage billing; control access, compliance, and security; and share resources across your AWS accounts.\nUsing AWS Organizations, you can automate account creation, create groups of accounts to reflect your business needs, and apply policies for these groups for governance.\n You can also simplify billing by setting up a single payment method for all of your AWS accounts.\n Through integrations with other AWS services, you can use AWS Organizations to define central configurations and resource sharing across accounts in your organization.\n AWS Organizations is available to all AWS customers at no additional charge.\nYou should create accounts per department based on regulatory restrictions (using Service Control Policies (SCP)) for better resource isolation, and to have separate per-account service limits.\nAWS Organizations allows you to restrict what services and actions are allowed in your accounts.\n You can use the Service Control Policies (SCP) to apply permission guardrails on AWS Identity and Access Management (IAM) users and roles.\n",
            "incorrect": "<strong>Never use tags for billing</strong> - You should use tags standards to categorize AWS resources for billing purposes.\n<strong>Disable AWS CloudTrail on several accounts</strong> - You should enable AWS CloudTrail to monitor activity on all accounts for governance, compliance, risk, and auditing purposes.\n<strong>Do not use AWS Organizations to automate AWS account creation</strong> - AWS Organizations helps you simplify IT operations by automating AWS account creation and management.\n The AWS Organizations APIs enable you to create new accounts programmatically and to add new accounts to a group.\n The policies attached to the group are automatically applied to the new account.\nReference:",
            "reference": "https://aws.amazon.com/organizations/"
        }
    },
    {
        "id": 18,
        "questions": [
            "Which of the following AWS authentication mechanisms supports an AWS Multi-Factor Authentication (AWS MFA) device that you can plug into a USB port on your computer?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "U2F security key",
                "check": true
            },
            {
                "answer": "Hardware Multi-Factor Authentication (AWS MFA) device",
                "check": false
            },
            {
                "answer": "SMS text message-based Multi-Factor Authentication (AWS MFA)",
                "check": false
            },
            {
                "answer": "Virtual Multi-Factor Authentication (AWS MFA) device",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>U2F security key</strong>Universal 2nd Factor (U2F) Security Key is a device that you can plug into a USB port on your computer.\n U2F is an open authentication standard hosted by the FIDO Alliance.\n When you enable a U2F security key, you sign in by entering your credentials and then tapping the device instead of manually entering a code.\n",
            "incorrect": "<strong>Virtual Multi-Factor Authentication (AWS MFA) device</strong> - This is a software app that runs on a phone or other device and emulates a physical device.\n The device generates a six-digit numeric code based upon a time-synchronized one-time password algorithm.\n The user must type a valid code from the device on a second webpage during sign-in.\n Each virtual MFA device assigned to a user must be unique.\n<strong>Hardware Multi-Factor Authentication (AWS MFA) device</strong> - This is a hardware device that generates a six-digit numeric code based upon a time-synchronized one-time password algorithm.\n The user must type a valid code from the device on a second webpage during sign-in.\n Each MFA device assigned to a user must be unique.\n A user cannot type a code from another user's device to be authenticated.\n<strong>SMS text message-based Multi-Factor Authentication (AWS MFA)</strong> - This is a type of MFA in which the IAM user settings include the phone number of the user's SMS-compatible mobile device.\n When the user signs in, AWS sends a six-digit numeric code by SMS text message to the user's mobile device.\n The user is required to type that code on a second webpage during sign-in.\nReferences:",
            "reference": "https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa_enable_u2f.html"
        }
    },
    {
        "id": 19,
        "questions": [
            "A company would like to separate cost for AWS services by the department for cost allocation. Which of the following is the simplest way to achieve this task?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "Create tags for each department",
                "check": true
            },
            {
                "answer": "Create one account for all departments and share this account",
                "check": false
            },
            {
                "answer": "Create different accounts for different departments",
                "check": false
            },
            {
                "answer": "Create different virtual private cloud (VPCs) for different departments",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>Create tags for each department</strong>You can assign metadata to your AWS resources in the form of tags.\n Each tag is a label consisting of a user-defined key and value.\n Tags can help you manage, identify, organize, search for, and filter resources.\n You can create tags to categorize resources by purpose, owner, environment, or other criteria.\nTypically, you use business tags such as cost center/business unit, customer, or project to associate AWS costs with traditional cost-allocation dimensions.\n But a cost allocation report can include any tag.\n This lets you associate costs with technical or security dimensions, such as specific applications, environments, or compliance programs.\n",
            "incorrect": "<strong>Create different accounts for different departments</strong> - Users can belong to several departments.\n Therefore, having different accounts for different departments would imply some users having several accounts.\n This is contrary to the security best practice: one physical user = one account.\n Also, it is much simpler to set up tags for tracking costs for each department.\n<strong>Create one account for all departments and share this account</strong> - Sharing accounts is not a security best practice, and is not recommended.\n<strong>Create different virtual private cloud (VPCs) for different departments</strong> - Creating different VPCs will not help with separating costs.\nReference:",
            "reference": "https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html"
        }
    },
    {
        "id": 20,
        "questions": [
            "Which service gives a personalized view of the status of the AWS services that are part of your Cloud architecture so that you can quickly assess the impact on your business when AWS service(s) are experiencing issues?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "Amazon CloudWatch",
                "check": false
            },
            {
                "answer": "Amazon Inspector",
                "check": false
            },
            {
                "answer": "AWS Health - Service Health Dashboard",
                "check": false
            },
            {
                "answer": "AWS Health - Your Account Health Dashboard",
                "check": true
            }
        ],
        "explanation": {
            "correct": "<strong>AWS Health - Your Account Health Dashboard</strong>AWS Health - Your Account Health Dashboard provides alerts and remediation guidance when AWS is experiencing events that may impact you.\nWith AWS Health - Your Account Health Dashboard, alerts are triggered by changes in the health of your AWS resources, giving you event visibility, and guidance to help quickly diagnose and resolve issues.\n",
            "incorrect": "<strong>Amazon Inspector</strong> - Amazon Inspector is an automated security assessment service that helps improve the security and compliance of applications deployed on AWS.\n Amazon Inspector automatically assesses applications for exposure, vulnerabilities, and deviations from best practices.\n Amazon Inspector cannot be used to prevent Distributed Denial-of-Service (DDoS) attack.\n It cannot provide the status of your AWS resources.\n<strong>Amazon CloudWatch</strong> - Amazon CloudWatch is a monitoring and observability service built for DevOps engineers, developers, site reliability engineers (SREs), and IT managers.\n CloudWatch provides data and actionable insights to monitor applications, respond to system-wide performance changes, optimize resource utilization, and get a unified view of operational health.\n This is an excellent service for building Resilient systems.\n Think resource performance monitoring, events, and alerts; think CloudWatch.\n It cannot provide the status of your AWS resources.\n<strong>AWS Health - Service Health Dashboard</strong> - The AWS Health - Service Health Dashboard is the single place to learn about the availability and operations of AWS services.\n You can view the overall status of AWS services, and you can sign in to view personalized communications about your particular AWS account or organization.\nExam Alert:While the AWS Health - Service Health Dashboard displays the general status of AWS services; the AWS Health - Your Account Health Dashboard gives you a personalized view of the performance and availability of the AWS services underlying your AWS resources.\nReference:",
            "reference": "https://docs.aws.amazon.com/health/latest/ug/what-is-aws-health.html"
        }
    },
    {
        "id": 21,
        "questions": [
            "A gaming company is looking at a technology/service that can deliver a consistent low-latency gameplay to ensure a great user experience for end-users in various locations.",
            "Which AWS technology/service will provide the necessary low-latency access to the end-users?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "AWS Edge Locations",
                "check": false
            },
            {
                "answer": "AWS Local Zones",
                "check": true
            },
            {
                "answer": "AWS Wavelength",
                "check": false
            },
            {
                "answer": "AWS Direct Connect",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>AWS Local Zones</strong>AWS Local Zones allow you to use select AWS services, like compute and storage services, closer to more end-users, providing them very low latency access to the applications running locally.\n AWS Local Zones are also connected to the parent region via Amazon’s redundant and very high bandwidth private network, giving applications running in AWS Local Zones fast, secure, and seamless access to the rest of AWS services.\nYou should use AWS Local Zones to deploy workloads closer to your end-users for low-latency requirements.\n AWS Local Zones have their connection to the internet and support AWS Direct Connect, so resources created in the Local Zone can serve local end-users with very low-latency communications.\nVarious AWS services such as Amazon Elastic Compute Cloud (EC2), Amazon Virtual Private Cloud (VPC), Amazon Elastic Block Store (EBS), Amazon FSx, Amazon Elastic Load Balancing, Amazon EMR, Amazon ElastiCache, and Amazon Relational Database Service (RDS) are available locally in the AWS Local Zones.\n You can also use services that orchestrate or work with local services such as Amazon EC2 Auto Scaling, Amazon EKS clusters, Amazon ECS clusters, Amazon EC2 Systems Manager, Amazon CloudWatch, AWS CloudTrail, and AWS CloudFormation.\n AWS Local Zones also provide a high-bandwidth, secure connection to the AWS Region, allowing you to seamlessly connect to the full range of services in the AWS Region through the same APIs and toolsets.\n",
            "incorrect": "<strong>AWS Edge Locations</strong> - An AWS Edge location is a site that CloudFront uses to cache copies of the content for faster delivery to users at any location.\n<strong>AWS Wavelength</strong> - AWS Wavelength extends the AWS cloud to a global network of 5G edge locations to enable developers to innovate and build a whole new class of applications that require ultra-low latency.\n Wavelength Zones provide a high-bandwidth, secure connection to the parent AWS Region, allowing developers to seamlessly connect to the full range of services in the AWS Region through the same APIs and toolsets.\n<strong>AWS Direct Connect</strong> - AWS Direct Connect is a cloud service that links your network directly to AWS, bypassing the internet to deliver more consistent, lower-latency performance.\n When creating a new connection, you can choose a hosted connection provided by an AWS Direct Connect Delivery Partner, or choose a dedicated connection from AWS—and deploy at over 100 AWS Direct Connect locations around the world.\n AWS Direct Connect provides consistently high bandwidth, low-latency access and it is generally used between on-premises data centers and AWS network.\n Direct Connect is overkill for the given requirement.\nReference:",
            "reference": "https://aws.amazon.com/about-aws/global-infrastructure/localzones/"
        }
    },
    {
        "id": 22,
        "questions": [
            "Which of the following AWS services can be used to forecast your AWS account usage and costs?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "AWS Cost & Usage Report (AWS CUR)",
                "check": false
            },
            {
                "answer": "AWS Budgets",
                "check": false
            },
            {
                "answer": "AWS Cost Explorer",
                "check": true
            },
            {
                "answer": "AWS Pricing Calculator",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>AWS Cost Explorer</strong>AWS Cost Explorer has an easy-to-use interface that lets you visualize, understand, and manage your AWS costs and usage over time.\n AWS Cost Explorer includes a default report that helps you visualize the costs and usage associated with your top five cost-accruing AWS services, and gives you a detailed breakdown of all services in the table view.\n The reports let you adjust the time range to view historical data going back up to twelve months to gain an understanding of your cost trends.\n AWS Cost Explorer also supports forecasting to get a better idea of what your costs and usage may look like in the future so that you can plan.\n",
            "incorrect": "<strong>AWS Cost &amp; Usage Report (AWS CUR)</strong> - The AWS Cost &amp; Usage Report (AWS CUR) contains the most comprehensive set of cost and usage data available.\n You can use Cost and Usage Reports to publish your AWS billing reports to an Amazon Simple Storage Service (Amazon S3) bucket that you own.\n You can receive reports that break down your costs by the hour or month, by product or product resource, or by tags that you define yourself.\n AWS updates the report in your bucket once a day in a comma-separated value (CSV) format.\n AWS Cost and Usage Reports cannot forecast your AWS account cost and usage.\n<strong>AWS Budgets</strong> - AWS Budgets gives the ability to set custom budgets that alert you when your costs or usage exceed (or are forecasted to exceed) your budgeted amount.\n You can also use AWS Budgets to set reservation utilization or coverage targets and receive alerts when your utilization drops below the threshold you define.\n Budgets can be created at the monthly, quarterly, or yearly level, and you can customize the start and end dates.\n You can further refine your budget to track costs associated with multiple dimensions, such as AWS service, linked account, tag, and others.\n  AWS Budgets cannot forecast your AWS account cost and usage.\n<strong>AWS Pricing Calculator</strong> - AWS Pricing Calculator lets you explore AWS services and create an estimate for the cost of your use cases on AWS.\n You can model your solutions before building them, explore the price points and calculations behind your estimate, and find the available instance types and contract terms that meet your needs.\n This enables you to make informed decisions about using AWS.\n You can plan your AWS costs and usage or price out setting up a new set of instances and services.\n You cannot use this service to forecast your AWS account cost and usage.\nReference:",
            "reference": "https://aws.amazon.com/aws-cost-management/aws-cost-explorer/"
        }
    },
    {
        "id": 23,
        "questions": [
            "Which of the following options is NOT a feature of Amazon Inspector?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "Track configuration changes",
                "check": true
            },
            {
                "answer": "Automate security assessments",
                "check": false
            },
            {
                "answer": "Inspect running operating systems (OS) against known vulnerabilities",
                "check": false
            },
            {
                "answer": "Analyze against unintended network accessibility",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>Track configuration changes</strong>Tracking configuration changes is a feature of AWS Config.\nAWS Config is a service that enables you to assess, audit, and evaluate the configurations of your AWS resources.\n Config continuously monitors and records your AWS resource configurations and allows you to automate the evaluation of recorded configurations against desired configurations.\n",
            "incorrect": "<strong>Automate security assessments</strong><strong>Analyze against unintended network accessibility</strong><strong>Inspect running operating systems (OS) against known vulnerabilities</strong>These options are all features of Amazon Inspector.\nAmazon Inspector is an automated security assessment service that helps improve the security and compliance of applications deployed on AWS.\n Amazon Inspector automatically assesses applications for exposure, vulnerabilities, and deviations from best practices.\nAmazon Inspector security assessments help you check for unintended network accessibility of your Amazon EC2 instances and for vulnerabilities on those EC2 instances.\nAmazon Inspector also offers predefined software called an agent that you can optionally install in the operating system of the EC2 instances that you want to assess.\n The agent monitors the behavior of the EC2 instances, including network, file system, and process activity.\n It also collects a wide set of behavior and configuration data (telemetry).\nReferences:",
            "reference": "https://aws.amazon.com/inspector/"
        }
    },
    {
        "id": 24,
        "questions": [
            "A Cloud Practitioner would like to deploy identical resources across all AWS regions and accounts using templates while estimating costs. Which AWS service can assist with this task?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "AWS CloudFormation",
                "check": true
            },
            {
                "answer": "AWS Directory Service for Microsoft Active Directory (AWS Managed Microsoft AD)",
                "check": false
            },
            {
                "answer": "AWS CodeDeploy",
                "check": false
            },
            {
                "answer": "Amazon LightSail",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>AWS CloudFormation</strong>AWS CloudFormation gives developers and systems administrators an easy way to create and manage a collection of related AWS resources, provisioning and updating them in an orderly and predictable fashion.\nYou can use the AWS CloudFormation sample templates or create your own templates to describe your AWS resources, and any associated dependencies or runtime parameters, required to run your application.\n This provides a single source of truth for all your resources and helps you to standardize infrastructure components used across your organization, enabling configuration compliance and faster troubleshooting.\nAWS CloudFormation templates allow you to estimate the cost of your resources.\n",
            "incorrect": "<strong>AWS Directory Service for Microsoft Active Directory (AWS Managed Microsoft AD)</strong> - AWS Directory Service for Microsoft Active Directory (AWS Managed Microsoft AD), also known as AWS Managed Microsoft AD, enables your directory-aware workloads and AWS resources to use managed Active Directory in the AWS Cloud.\n It is not used to deploy resources.\n<strong>Amazon LightSail</strong> - Amazon Lightsail is designed to be the easiest way to launch and manage a virtual private server with AWS.\n It is not best suited when deploying more complex resources, while AWS CloudFormation can.\n<strong>AWS CodeDeploy</strong> - AWS CodeDeploy is a service that automates code deployments to any instance, including Amazon EC2 instances and instances running on-premises.\n Unlike AWS CloudFormation, it does not deal with infrastructure configuration and orchestration.\nReference:",
            "reference": "https://aws.amazon.com/cloudformation/"
        }
    },
    {
        "id": 25,
        "questions": [
            "Which of the following AWS services offer block-level storage? (Select two)"
        ],
        "single_choice": false,
        "answers": [
            {
                "answer": "Amazon Simple Storage Service (Amazon S3)",
                "check": false
            },
            {
                "answer": "Amazon Elastic Block Store (Amazon EBS)",
                "check": true
            },
            {
                "answer": "Amazon Elastic Container Service (Amazon ECS)",
                "check": false
            },
            {
                "answer": "Amazon Elastic File System (Amazon EFS)",
                "check": false
            },
            {
                "answer": "Instance Store",
                "check": true
            }
        ],
        "explanation": {
            "correct": "<strong>Amazon Elastic Block Store (Amazon EBS)</strong>Amazon Elastic Block Store (Amazon EBS) is an easy to use, high-performance block storage service designed for use with Amazon Elastic Compute Cloud (Amazon EC2) for both throughput and transaction-intensive workloads at any scale.\n A broad range of workloads, such as relational and non-relational databases, enterprise applications, containerized applications, big data analytics engines, file systems, and media workflows are widely deployed on Amazon EBS.\n<strong>Instance Store</strong>An instance store provides temporary block-level storage for your EC2 instance.\n This storage is located on disks that are physically attached to the host computer.\n Instance store is ideal for the temporary storage of information that changes frequently, such as buffers, caches, scratch data, and other temporary content, or for data that is replicated across a fleet of instances, such as a load-balanced pool of web servers.\n Instance storage is temporary, data is lost if instance experiences failure or is terminated.\n Amazon EC2 instance store cannot be used for file sharing between instances.\n",
            "incorrect": "<strong>Amazon Elastic File System (Amazon EFS)</strong> - Amazon Elastic File System (Amazon EFS) provides a simple, scalable, fully managed, elastic NFS file system.\n It is built to scale on-demand to petabytes without disrupting applications, growing and shrinking automatically as you add and remove files, eliminating the need to provision and manage capacity to accommodate growth.\n Amazon EFS is designed to provide massively parallel shared access to thousands of Amazon EC2 instances, enabling your applications to achieve high levels of aggregate throughput and IOPS with consistent low latencies.\n<strong>Amazon Simple Storage Service (Amazon S3)</strong> - Amazon Simple Storage Service (Amazon S3) is an object storage service that offers industry-leading scalability, data availability, security, and performance.\n This means customers of all sizes and industries can use it to store and protect any amount of data for a range of use cases, such as websites, mobile applications, backup and restore, archive, enterprise applications, IoT devices, and big data analytics.\n<strong>Amazon Elastic Container Service (Amazon ECS)</strong> - Amazon Elastic Container Service (Amazon ECS) is a highly scalable, high-performance container management service that supports Docker containers and allows you to easily run applications on a managed cluster of Amazon EC2 instances.\n This is not a storage service and has been added as a distractor.\nReferences:",
            "reference": "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html"
        }
    },
    {
        "id": 26,
        "questions": [
            "A startup wants to provision an EC2 instance for the lowest possible cost for a long-term duration but needs to make sure that the instance would never be interrupted. As a Cloud Practitioner, which of the following options would you recommend?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "EC2 On-Demand Instance",
                "check": false
            },
            {
                "answer": "EC2 Reserved Instance (RI)",
                "check": true
            },
            {
                "answer": "EC2 Spot Instance",
                "check": false
            },
            {
                "answer": "EC2 Dedicated Host",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>EC2 Reserved Instance (RI)</strong>An EC2 Reserved Instance (RI) provides you with significant savings (up to 75%) on your Amazon EC2 costs compared to On-Demand Instance pricing.\n A Reserved Instance (RI) is not a physical instance, but rather a billing discount applied to the use of On-Demand Instances in your account.\n You can purchase a Reserved Instance (RI) for a one-year or three-year commitment, with the three-year commitment offering a bigger discount.\n A reserved instance (RI) cannot be interrupted.\n So this is the correct option.\n",
            "incorrect": "<strong>EC2 On-Demand Instance</strong> - An EC2 On-Demand Instance is an instance that you use on-demand.\n You have full control over its lifecycle — you decide when to launch, stop, hibernate, start, reboot, or terminate it.\n There is no long-term commitment required when you purchase On-Demand Instances.\n There is no upfront payment and you pay only for the seconds that your On-Demand Instances are running.\n The price per second for running an On-Demand Instance is fixed.\n On-demand instances cannot be interrupted.\n However, On-demand instances are not as cost-effective as Reserved instances, so this option is not correct.\n<strong>EC2 Spot Instance</strong> - An EC2 Spot Instance is an unused EC2 instance that is available for less than the On-Demand price.\n Because Spot Instances enable you to request unused EC2 instances at steep discounts (up to 90%), you can lower your Amazon EC2 costs significantly.\n Spot Instances are well-suited for data analysis, batch jobs, background processing, and optional tasks.\n These can be terminated at short notice, so these are not suitable for critical workloads that need to run at a specific point in time.\n So this option is not correct for the given use-case.\n<strong>EC2 Dedicated Host</strong> - An Amazon EC2 Dedicated Host allows you to use your eligible software licenses from vendors such as Microsoft and Oracle on Amazon EC2 so that you get the flexibility and cost-effectiveness of using your licenses, but with the resiliency, simplicity, and elasticity of AWS.\n An Amazon EC2 Dedicated Host is a physical server fully dedicated for your use, so you can help address corporate compliance requirement.\n It is not cost-efficient compared to an On-Demand instance.\n So this option is not correct.\nReference:",
            "reference": "https://aws.amazon.com/ec2/pricing/"
        }
    },
    {
        "id": 27,
        "questions": [
            "Which AWS service can be used to subscribe to an RSS feed to be notified of the status of all AWS service interruptions?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "AWS Health Dashboard - Your Account Health",
                "check": false
            },
            {
                "answer": "AWS Health Dashboard - Service Health",
                "check": true
            },
            {
                "answer": "Amazon Simple Notification Service (Amazon SNS)",
                "check": false
            },
            {
                "answer": "AWS Lambda",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>AWS Health Dashboard - Service Health</strong>The AWS Health Dashboard – Service health is the single place to learn about the availability and operations of AWS services.\n You can view the overall status of AWS services, and you can sign in to view personalized communications about your particular AWS account or organization.\nThe AWS Health Dashboard – Service health offers the possibility to subscribe to an RSS feed to be notified of interruptions to each service.\n",
            "incorrect": "<strong>Amazon Simple Notification Service (Amazon SNS)</strong> - Amazon Simple Notification Service (Amazon SNS) is a highly available, durable, secure, fully managed pub/sub messaging service that enables you to decouple microservices, distributed systems, and serverless applications.\n It can be used to deliver notifications, but it does not provide the current services' status.\n<strong>AWS Health Dashboard - Your Account Health</strong> - Your AWS Health Dashboard – Your Account Health provides alerts and remediation guidance when AWS is experiencing events that may impact you.\n<strong>AWS Lambda</strong> - AWS Lambda lets you run code without provisioning or managing servers.\n It does not provide all AWS services' status.\nReference:",
            "reference": "https://health.aws.amazon.com/health/status"
        }
    },
    {
        "id": 28,
        "questions": [
            "A company's flagship application runs on a fleet of Amazon Elastic Compute Cloud (Amazon EC2) instances. As per the new policies, the system administrators are looking for the best way to provide secure shell access to Amazon Elastic Compute Cloud (Amazon EC2) instances without opening new ports or using public IP addresses.",
            "Which tool/service will help you achieve this requirement?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "AWS Systems Manager Session Manager",
                "check": true
            },
            {
                "answer": "Amazon Inspector",
                "check": false
            },
            {
                "answer": "Amazon Route 53",
                "check": false
            },
            {
                "answer": "Amazon Elastic Compute Cloud (Amazon EC2) Instance Connect",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>AWS Systems Manager Session Manager</strong>AWS Systems Manager Session Manager is a fully-managed service that provides you with an interactive browser-based shell and CLI experience.\n It helps provide secure and auditable instance management without the need to open inbound ports, maintain bastion hosts, and manage SSH keys.\n AWS Systems Manager Session Manager helps to enable compliance with corporate policies that require controlled access to instances, increase security and auditability of access to the instances while providing simplicity and cross-platform instance access to end-users.\n",
            "incorrect": "<strong>Amazon Elastic Compute Cloud (Amazon EC2) Instance Connect</strong> - Amazon Elastic Compute Cloud (Amazon EC2) Instance Connect provides a simple and secure way to connect to your Linux instances using Secure Shell (SSH).\n With EC2 Instance Connect, you use AWS Identity and Access Management (IAM) policies and principals to control SSH access to your instances, removing the need to share and manage SSH keys.\n EC2 Instance Connect will need port 22 to be open for traffic.\n Therefore, not the correct option here.\n<strong>Amazon Inspector</strong> - Amazon Inspector is an automated security assessment service that helps improve the security and compliance of applications deployed on AWS.\n Amazon Inspector automatically assesses applications for exposure, vulnerabilities, and deviations from best practices.\n After performing an assessment, Amazon Inspector produces a detailed list of security findings prioritized by level of severity.\n Amazon Inspector cannot provide secure shell access to EC2 instances.\n<strong>Amazon Route 53</strong> - Amazon Route 53 is a highly available and scalable cloud Domain Name System (DNS) web service.\n It is designed to give developers and businesses an extremely reliable and cost-effective way to route end users to Internet applications by translating names like www.\nexample.\ncom into the numeric IP addresses like 192.\n0.\n2.\n1 that computers use to connect to each other.\n Amazon Route 53 cannot provide secure shell access to EC2 instances.\nReference:",
            "reference": "https://aws.amazon.com/systems-manager/faq/"
        }
    },
    {
        "id": 29,
        "questions": [
            "A company wants to improve the resiliency of its flagship application so it wants to move from its traditional database system to a managed AWS NoSQL database service to support active-active configuration in both the East and West US AWS regions. The active-active configuration with cross-region support is the prime criteria for any database solution that the company considers.",
            "Which AWS database service is the right fit for this requirement?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "Amazon Aurora with multi-master clusters",
                "check": false
            },
            {
                "answer": "Amazon Relational Database Service (Amazon RDS) for MYSQL",
                "check": false
            },
            {
                "answer": "Amazon DynamoDB with DynamoDB Accelerator",
                "check": false
            },
            {
                "answer": "Amazon DynamoDB with global tables",
                "check": true
            }
        ],
        "explanation": {
            "correct": "<strong>Amazon DynamoDB with global tables</strong>Amazon DynamoDB is a fully managed, serverless, key-value NoSQL database designed to run high-performance applications at any scale.\n DynamoDB offers built-in security, continuous backups, automated multi-region replication, in-memory caching, and data export tools.\nDynamoDB global tables replicate data automatically across your choice of AWS Regions and automatically scale capacity to accommodate your workloads.\n With global tables, your globally distributed applications can access data locally in the selected regions to get single-digit millisecond read and write performance.\n DynamoDB offers active-active cross-region support that is needed for the company.\n",
            "incorrect": "<strong>Amazon DynamoDB with DynamoDB Accelerator</strong> - DynamoDB Accelerator (DAX) is an in-memory cache that delivers fast read performance for your tables at scale by enabling you to use a fully managed in-memory cache.\n Using DAX, you can improve the read performance of your DynamoDB tables by up to 10 times—taking the time required for reads from milliseconds to microseconds, even at millions of requests per second.\n DAX does not offer active-active cross-Region configuration.\n<strong>Amazon Aurora with multi-master clusters</strong> - Amazon Aurora (Aurora) is a fully managed relational database engine that's compatible with MySQL and PostgreSQL.\n With some workloads, Aurora can deliver up to five times the throughput of MySQL and up to three times the throughput of PostgreSQL without requiring changes to most of your existing applications.\n In a multi-master cluster, all DB instances have read/write capability.\n Aurora is not a NoSQL database, so this option is incorrect.\n<strong>Amazon Relational Database Service (Amazon RDS) for MYSQL</strong> - Amazon Relational Database Service (Amazon RDS) makes it easy to set up, operate, and scale a relational database in the cloud.\n It provides cost-efficient and resizable capacity while automating time-consuming administration tasks such as hardware provisioning, database setup, patching and backups.\n It frees you to focus on your applications so you can give them the fast performance, high availability, security and compatibility they need.\n RDS is not a NoSQL database, so this option is incorrect.\nReferences:",
            "reference": "https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-multi-master.html"
        }
    },
    {
        "id": 30,
        "questions": [
            "Which entity ensures that your application on Amazon Elastic Compute Cloud (Amazon EC2) always has the right amount of capacity to handle the current traffic demand?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "Multi-AZ deployment",
                "check": false
            },
            {
                "answer": "Network Load Balancer",
                "check": false
            },
            {
                "answer": "Application Load Balancer",
                "check": false
            },
            {
                "answer": "Amazon EC2 Auto Scaling",
                "check": true
            }
        ],
        "explanation": {
            "correct": "<strong>Amazon EC2 Auto Scaling</strong>Amazon EC2 Auto Scaling helps you ensure that you have the correct number of Amazon EC2 instances available to handle the load for your application.\n You create collections of Amazon EC2 instances, called Auto Scaling groups.\n You can specify the minimum number of instances in each Auto Scaling group, and Amazon EC2 Auto Scaling ensures that your group never goes below this size.\n",
            "incorrect": "<strong>Multi-AZ deployment</strong> - With Availability Zones (AZ), you can design and operate applications and databases that automatically failover between zones without interruption.\n Multi-AZ deployment of Amazon EC2 instances provided high availability, it does not help in scaling resources.\n<strong>Network Load Balancer</strong> - Network Load Balancer is best suited for load balancing of Transmission Control Protocol (TCP), User Datagram Protocol (UDP) and Transport Layer Security (TLS) traffic where extreme performance is required.\n It distributes traffic, does not scale resources.\n<strong>Application Load Balancer</strong> - An Application Load Balancer serves as the single point of contact for clients.\n The load balancer distributes incoming application traffic across multiple targets, such as EC2 instances, in multiple Availability Zones.\n It distributes traffic, does not scale resources.\nReference:",
            "reference": "https://docs.aws.amazon.com/autoscaling/ec2/userguide/what-is-amazon-ec2-auto-scaling.html"
        }
    },
    {
        "id": 31,
        "questions": [
            "A corporation would like to simplify access management to multiple AWS accounts as well as facilitate AWS Single Sign-On (AWS SSO) access to its AWS accounts. As a Cloud Practitioner, which AWS service would you use for this task?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "AWS Cognito",
                "check": false
            },
            {
                "answer": "AWS Command Line Interface (CLI)",
                "check": false
            },
            {
                "answer": "AWS Identity and Access Management (AWS IAM)",
                "check": false
            },
            {
                "answer": "AWS IAM Identity Center",
                "check": true
            }
        ],
        "explanation": {
            "correct": "<strong>AWS IAM Identity Center</strong>AWS IAM Identity Center is the successor to AWS Single Sign-On (AWS SSO).\n It is built on top of AWS Identity and Access Management (IAM) to simplify access management to multiple AWS accounts, AWS applications, and other SAML-enabled cloud applications.\n In IAM Identity Center, you create or connect, your workforce users for use across AWS.\n You can choose to manage access just to your AWS accounts, just to your cloud applications, or to both.\nYou can create users directly in IAM Identity Center, or you can bring them from your existing workforce directory.\n With IAM Identity Center, you get a unified administration experience to define, customize, and assign fine-grained access.\n Your workforce users get a user portal to access their assigned AWS accounts or cloud applications.\nYou can use IAM Identity Center to quickly and easily assign and manage your employees’ access to multiple AWS accounts, SAML-enabled cloud applications (such as Salesforce, Microsoft 365, and Box), and custom-built in-house applications, all from a central place.\n",
            "incorrect": "<strong>AWS Cognito</strong> - Amazon Cognito lets you add user sign-up, sign-in, and access control to your web and mobile apps quickly and easily.\n With Amazon Cognito, you also have the option to authenticate users through social identity providers such as Facebook, Twitter, or Amazon, with SAML identity solutions, or by using your own identity system.\n It is an identity management solution for customers/developers building B2C or B2B apps for their customers.\n<strong>AWS Identity and Access Management (AWS IAM)</strong> - AWS Identity and Access Management (AWS IAM) enables you to securely control access to AWS services and resources for your users.\n Using AWS IAM, you can create and manage AWS users and groups, and use permissions to allow and deny their access to AWS resources.\n It is not used to log in but to manage users and roles.\n<strong>AWS Command Line Interface (CLI)</strong> - The AWS Command Line Interface (CLI) is a unified tool to manage your AWS services.\n With just one tool to download and configure, you can control multiple AWS services from the command line and automate them through scripts.\n It is not a central user portal.\nReference:",
            "reference": "https://aws.amazon.com/iam/identity-center/"
        }
    },
    {
        "id": 32,
        "questions": [
            "An organization maintains a separate Virtual Private Cloud (VPC) for each of its business units. Two units need to privately share data. Which is the most optimal way of privately sharing data between the two VPCs?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "VPC Endpoint",
                "check": false
            },
            {
                "answer": "AWS Site-to-Site VPN",
                "check": false
            },
            {
                "answer": "AWS Direct Connect",
                "check": false
            },
            {
                "answer": "VPC peering connection",
                "check": true
            }
        ],
        "explanation": {
            "correct": "<strong>VPC peering connection</strong>A VPC peering connection is a networking connection between two VPCs that enables you to route traffic between them privately.\n Instances in either VPC can communicate with each other as if they are within the same network.\n You can create a VPC peering connection between your VPCs, with a VPC in another AWS account, or with a VPC in a different AWS Region.\n",
            "incorrect": "<strong>AWS Site-to-Site VPN</strong> - AWS Site-to-Site VPN creates a secure connection between your data center or branch office and your AWS cloud resources.\n This connection goes over the public internet.\n Site to Site VPN cannot be used to interconnect VPCs.\n<strong>AWS Direct Connect</strong> - AWS Direct Connect creates a dedicated private connection from a remote network to your VPC.\n This is a private connection and does not use the public internet.\n Takes at least a month to establish this connection.\n AWS Direct Connect cannot be used to interconnect VPCs.\n<strong>VPC Endpoint</strong> - A VPC endpoint enables you to privately connect your VPC to supported AWS services and VPC endpoint services powered by AWS PrivateLink without requiring an internet gateway, NAT device, VPN connection, or AWS Direct Connect connection.\n You cannot connect two VPCs using a VPC endpoint.\nReference:",
            "reference": "https://docs.aws.amazon.com/vpc/latest/peering/what-is-vpc-peering.html"
        }
    },
    {
        "id": 33,
        "questions": [
            "Which AWS Route 53 routing policy would you use to route traffic to multiple resources and also choose how much traffic is routed to each resource?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "Weighted routing",
                "check": true
            },
            {
                "answer": "Simple routing",
                "check": false
            },
            {
                "answer": "latency-based routing",
                "check": false
            },
            {
                "answer": "Failover routing",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>Weighted routing</strong>Amazon Route 53 is a highly available and scalable cloud Domain Name System (DNS) web service.\n It is designed to give developers and businesses an extremely reliable and cost-effective way to route end users to Internet applications by translating names like www.\nexample.\ncom into the numeric IP addresses like 192.\n0.\n2.\n1 that computers use to connect to each other.\nWeighted routing lets you associate multiple resources with a single domain name (example.\ncom) or subdomain name (acme.\nexample.\ncom) and choose how much traffic is routed to each resource.\n This can be useful for a variety of purposes, including load balancing and testing new versions of software.\n To configure weighted routing, you create records that have the same name and type for each of your resources.\n You assign each record a relative weight that corresponds with how much traffic you want to send to each resource.\n Amazon Route 53 sends traffic to a resource based on the weight that you assign to the record as a proportion of the total weight for all records in the group.\n",
            "incorrect": "<strong>Failover routing</strong> - This routing policy is used when you want to configure active-passive failover.\n<strong>Simple routing</strong> - With simple routing, you typically route traffic to a single resource, for example, to a web server for your website.\n<strong>latency-based routing</strong> - This routing policy is used when you have resources in multiple AWS Regions and you want to route traffic to the region that provides the best latency.\nReference:",
            "reference": "https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html"
        }
    },
    {
        "id": 34,
        "questions": [
            "A Cloud Practitioner would like to get operational insights of its resources to quickly identify any issues that might impact applications using those resources. Which AWS service can help with this task?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "AWS Systems Manager",
                "check": true
            },
            {
                "answer": "Amazon Inspector",
                "check": false
            },
            {
                "answer": "AWS Health Dashboard - Your Account Health",
                "check": false
            },
            {
                "answer": "AWS Trusted Advisor",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>AWS Systems Manager</strong>AWS Systems Manager allows you to centralize operational data from multiple AWS services and automate tasks across your AWS resources.\n You can create logical groups of resources such as applications, different layers of an application stack, or production versus development environments.\nWith AWS Systems Manager, you can select a resource group and view its recent API activity, resource configuration changes, related notifications, operational alerts, software inventory, and patch compliance status.\n You can also take action on each resource group depending on your operational needs.\n AWS Systems Manager provides a central place to view and manage your AWS resources, so you can have complete visibility and control over your operations.\n",
            "incorrect": "<strong>Amazon Inspector</strong> - Amazon Inspector is an automated security assessment service that helps improve the security and compliance of applications deployed on AWS.\n It is not used to get operational insights of AWS resources.\n<strong>AWS Health Dashboard - Your Account Health</strong> - AWS Health Dashboard - Your Account Health provides alerts and remediation guidance when AWS is experiencing events that may impact you.\n It is not used to get operational insights of AWS resources.\n<strong>AWS Trusted Advisor</strong> - AWS Trusted Advisor is an online resource to help you reduce cost, increase performance, and improve security by optimizing your AWS environment.\n AWS Trusted Advisor provides real-time guidance to help you provision your resources following AWS best practices.\n It is not used to get operational insights of AWS resources.\nReference:",
            "reference": "https://aws.amazon.com/systems-manager/"
        }
    },
    {
        "id": 35,
        "questions": [
            "A start-up would like to quickly deploy a popular technology on AWS. As a Cloud Practitioner, which AWS tool would you use for this task?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "AWS Forums",
                "check": false
            },
            {
                "answer": "AWS Whitepapers",
                "check": false
            },
            {
                "answer": "AWS Partner Solutions (formerly Quick Starts)",
                "check": true
            },
            {
                "answer": "AWS CodeDeploy",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>AWS Partner Solutions (formerly Quick Starts)</strong>AWS Partner Solutions are automated reference deployments built by Amazon Web Services (AWS) solutions architects and AWS Partners.\n Partner Solutions help you deploy popular technologies to AWS according to AWS best practices.\n You can reduce hundreds of manual procedures to a few steps and start using your environment within minutes.\nAWS Partner Solutions are automated reference deployments for key workloads on the AWS Cloud.\n Each Partner Solution launches, configures, and runs the AWS compute, network, storage, and other services required to deploy a specific workload on AWS, using AWS best practices for security and availability.\n",
            "incorrect": "<strong>AWS Forums</strong> - AWS Forums is an AWS community platform where people can help each other.\n It is not used to deploy technologies on AWS.\n<strong>AWS CodeDeploy</strong> - AWS CodeDeploy is a service that automates code deployments to any instance, including Amazon EC2 instances and instances running on-premises.\n It is not suited to rapidly deploy popular technologies on AWS ready to be used immediately.\n<strong>AWS Whitepapers</strong> - AWS Whitepapers are technical content authored by AWS and the AWS community to expand your knowledge of the cloud.\n They include technical whitepapers, technical guides, reference material, and reference architecture diagrams.\n You can find useful content for your deployment, but it is not a service that will deploy technologies.\nReference:",
            "reference": "https://aws.amazon.com/quickstart/"
        }
    },
    {
        "id": 36,
        "questions": [
            "Which of the following options are the benefits of using AWS Elastic Load Balancing (ELB)? (Select TWO)"
        ],
        "single_choice": false,
        "answers": [
            {
                "answer": "High availability",
                "check": true
            },
            {
                "answer": "Fault tolerance",
                "check": true
            },
            {
                "answer": "Agility",
                "check": false
            },
            {
                "answer": "Storage",
                "check": false
            },
            {
                "answer": "Less costly",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>High availability</strong><strong>Fault tolerance</strong>Elastic Load Balancing (ELB) automatically distributes incoming application traffic across multiple targets, such as Amazon EC2 instances, containers, and IP addresses.\n It can handle the varying load of your application traffic in a single Availability Zone (AZ) or across multiple Availability Zones (AZs).\nElastic Load Balancing (ELB) offers three types of load balancers that all feature the high availability, automatic scaling, and robust security necessary to make your applications fault-tolerant: Application Load Balancer (best suited for HTTP and HTTPS traffic), Network Load Balancer (best suited for TCP traffic), and Classic Load Balancer.\n",
            "incorrect": "<strong>Agility</strong> - Agility refers to new IT resources being only a click away, which means that you reduce the time to make those resources available to your developers from weeks to just minutes.\n AWS Elastic Load Balancing (ELB) does not help with agility.\n<strong>Less costly</strong> - AWS Elastic Load Balancing (ELB) does not help with reducing costs.\n<strong>Storage</strong> - AWS Elastic Load Balancing (ELB) does not offer storage benefits.\n It is not a storage-related service.\nReference:",
            "reference": "https://aws.amazon.com/elasticloadbalancing/"
        }
    },
    {
        "id": 37,
        "questions": [
            "An intern at an IT company provisioned a Linux based On-demand EC2 instance with per-second billing but terminated it within 30 seconds as he wanted to provision another instance type. What is the duration for which the instance would be charged?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "300 seconds",
                "check": false
            },
            {
                "answer": "30 seconds",
                "check": false
            },
            {
                "answer": "600 seconds",
                "check": false
            },
            {
                "answer": "60 seconds",
                "check": true
            }
        ],
        "explanation": {
            "correct": "<strong>60 seconds</strong>There is a one-minute minimum charge for Linux based EC2 instances, so this is the correct option.\n",
            "incorrect": "<strong>30 seconds</strong><strong>300 seconds</strong><strong>600 seconds</strong>These three options contradict the details provided earlier in the explanation, so these options are incorrect.\nReference:",
            "reference": "https://aws.amazon.com/blogs/aws/new-per-second-billing-for-ec2-instances-and-ebs-volumes/"
        }
    },
    {
        "id": 38,
        "questions": [
            "Due to regulatory and compliance reasons, an organization is supposed to use a hardware device for any data encryption operations in the cloud. Which AWS service can be used to meet this compliance requirement?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "AWS CloudHSM",
                "check": true
            },
            {
                "answer": "AWS Trusted Advisor",
                "check": false
            },
            {
                "answer": "AWS Key Management Service (AWS KMS)",
                "check": false
            },
            {
                "answer": "AWS Secrets Manager",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>AWS CloudHSM</strong>AWS CloudHSM is a cloud-based Hardware Security Module (HSM) that enables you to easily generate and use your encryption keys on the AWS Cloud.\n With CloudHSM, you can manage your encryption keys using FIPS 140-2 Level 3 validated HSMs.\n It is a fully-managed service that automates time-consuming administrative tasks for you, such as hardware provisioning, software patching, high-availability, and backups.\n",
            "incorrect": "<strong>AWS Key Management Service (AWS KMS)</strong> - AWS Key Management Service (AWS KMS) makes it easy for you to create and manage cryptographic keys and control their use across a wide range of AWS services and in your applications.\n It is a secure and resilient service that uses hardware security modules that have been validated under FIPS 140-2, or are in the process of being validated, to protect your keys.\n It cannot be used as a Hardware Security Module for data encryption operations in AWS Cloud.\n<strong>AWS Secrets Manager</strong> - AWS Secrets Manager helps you protect secrets needed to access your applications, services, and IT resources.\n The service enables you to easily rotate, manage, and retrieve database credentials, API keys, and other secrets throughout their lifecycle.\n Users and applications retrieve secrets with a call to Secrets Manager APIs, eliminating the need to hardcode sensitive information in plain text.\n Secrets Manager cannot be used as a Hardware Security Module for data encryption operations in AWS Cloud.\n<strong>AWS Trusted Advisor</strong> - AWS Trusted Advisor is an online tool that provides you real-time guidance to help you provision your resources following AWS best practices on cost optimization, security, fault tolerance, service limits, and performance improvement.\n Whether establishing new workflows, developing applications, or as part of ongoing improvement, recommendations provided by Trusted Advisor regularly help keep your solutions provisioned optimally.\nReference:",
            "reference": "https://aws.amazon.com/cloudhsm/"
        }
    },
    {
        "id": 39,
        "questions": [
            "An IT company has a hybrid cloud architecture and it wants to centralize the server logs for its Amazon Elastic Compute Cloud (Amazon EC2) instances and on-premises servers. Which of the following is the MOST effective for this use-case?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "Use Amazon CloudWatch Logs for both the Amazon Elastic Compute Cloud (Amazon EC2) instance and the on-premises servers",
                "check": true
            },
            {
                "answer": "Use Amazon CloudWatch Logs for the Amazon Elastic Compute Cloud (Amazon EC2) instance and AWS CloudTrail for the on-premises servers",
                "check": false
            },
            {
                "answer": "Use AWS Lambda to send log data from Amazon Elastic Compute Cloud (Amazon EC2) instance as well as on-premises servers to Amazon CloudWatch Logs",
                "check": false
            },
            {
                "answer": "Use AWS CloudTrail for the Amazon Elastic Compute Cloud (Amazon EC2) instance and Amazon CloudWatch Logs for the on-premises servers",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>Use Amazon CloudWatch Logs for both the Amazon Elastic Compute Cloud (Amazon EC2) instance and the on-premises servers</strong>You can use Amazon CloudWatch Logs to monitor, store, and access your log files from Amazon Elastic Compute Cloud (Amazon EC2) instances, AWS CloudTrail, Route 53, and other sources such as on-premises servers.\nAmazon CloudWatch Logs enables you to centralize the logs from all of your systems, applications, and AWS services that you use, in a single, highly scalable service.\n You can then easily view them, search them for specific error codes or patterns, filter them based on specific fields, or archive them securely for future analysis.\n",
            "incorrect": "<strong>Use AWS Lambda to send log data from Amazon Elastic Compute Cloud (Amazon EC2) instance as well as on-premises servers to Amazon CloudWatch Logs</strong>AWS Lambda lets you run code without provisioning or managing servers.\n You pay only for the compute time you consume.\n Lambda cannot be used to centralize the logs from Amazon Elastic Compute Cloud (Amazon EC2) instances and on-premises servers.\n<strong>Use Amazon CloudWatch Logs for the Amazon Elastic Compute Cloud (Amazon EC2) instance and AWS CloudTrail for the on-premises servers</strong><strong>Use AWS CloudTrail for the Amazon Elastic Compute Cloud (Amazon EC2) instance and Amazon CloudWatch Logs for the on-premises servers</strong>AWS CloudTrail is a service that enables governance, compliance, operational auditing, and risk auditing of your AWS account.\n With AWS CloudTrail, you can log, continuously monitor, and retain account activity related to actions across your AWS infrastructure.\n AWS CloudTrail provides event history of your AWS account activity, including actions taken through the AWS Management Console, AWS SDKs, command-line tools, and other AWS services.\n AWS CloudTrail cannot be used to centralize the server logs for Amazon Elastic Compute Cloud (Amazon EC2) instances or on-premises servers, so both these options are incorrect.\nReferences:",
            "reference": "https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AgentReference.html"
        }
    },
    {
        "id": 40,
        "questions": [
            "Which of the following is a container service of AWS?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "AWS Elastic Beanstalk",
                "check": false
            },
            {
                "answer": "Amazon SageMaker",
                "check": false
            },
            {
                "answer": "Amazon Simple Notification Service (Amazon SNS)",
                "check": false
            },
            {
                "answer": "AWS Fargate",
                "check": true
            }
        ],
        "explanation": {
            "correct": "<strong>AWS Fargate</strong>AWS Fargate is a serverless compute engine for containers that works with both Amazon Elastic Container Service (ECS) and Amazon Elastic Kubernetes Service (EKS).\n Fargate makes it easy for you to focus on building your applications.\n Fargate removes the need to provision and manage servers, lets you specify and pay for resources per application, and improves security through application isolation by design.\n",
            "incorrect": "<strong>AWS Elastic Beanstalk</strong> - AWS Elastic Beanstalk is an easy-to-use service for deploying and scaling web applications and services.\n You simply upload your code and Elastic Beanstalk automatically handles the deployment, from capacity provisioning, load balancing, auto-scaling to application health monitoring.\n Beanstalk provisions servers so it is not a serverless service.\n<strong>Amazon Simple Notification Service (Amazon SNS)</strong> - Amazon Simple Notification Service (Amazon SNS) is a highly available, durable, secure, fully managed pub/sub messaging service that enables you to decouple microservices, distributed systems, and serverless applications.\n<strong>Amazon SageMaker</strong> - Amazon SageMaker is a fully managed service that provides every developer and data scientist with the ability to build, train, and deploy machine learning (ML) models quickly.\n SageMaker removes the heavy lifting from each step of the machine learning process to make it easier to develop high-quality models.\nReference:",
            "reference": "https://aws.amazon.com/fargate/"
        }
    },
    {
        "id": 41,
        "questions": [
            "An e-commerce company wants to store data from a recommendation engine in a database. As a Cloud Practioner, which AWS service would you recommend to provide this functionality with the LEAST operational overhead for any scale?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "Amazon DynamoDB",
                "check": true
            },
            {
                "answer": "Amazon Simple Storage Service (Amazon S3)",
                "check": false
            },
            {
                "answer": "Amazon Relational Database Service (Amazon RDS)",
                "check": false
            },
            {
                "answer": "Amazon Neptune",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>Amazon DynamoDB</strong>Amazon DynamoDB is a key-value and document database that delivers sub-millisecond performance at any scale.\n Amazon DynamoDB enables customers to offload the administrative burdens of operating and scaling distributed databases to AWS so that they don’t have to worry about hardware provisioning, setup and configuration, throughput capacity planning, replication, software patching, or cluster scaling.\nYou can use Amazon DynamoDB to store recommendation results with the LEAST operational overhead for any scale.\n",
            "incorrect": "<strong>Amazon Relational Database Service (Amazon RDS)</strong> - Amazon Relational Database Service (Amazon RDS) is a relational database service from AWS.\n Amazon RDS is less operationally efficient than Amazon DynamoDB while building a highly scalable solution.\n<strong>Amazon Simple Storage Service (Amazon S3)</strong> - Amazon Simple Storage Service (Amazon S3) is an object storage service and not a database service.\n<strong>Amazon Neptune</strong> - Amazon Neptune is a fully managed database service built for the cloud that makes it easier to build and run graph applications.\n It's not the right fit to store recommendation results with the LEAST operational overhead for any scale.\nReference:",
            "reference": "https://catalog.us-east-1.prod.workshops.aws/workshops/ed82a5d4-6630-41f0-a6a1-9345898fa6ec/en-US/batch/dynamodb"
        }
    },
    {
        "id": 42,
        "questions": [
            "Which AWS service can be used to automate code deployment to Amazon Elastic Compute Cloud (Amazon EC2) instances as well as on-premises instances?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "AWS CodePipeline",
                "check": false
            },
            {
                "answer": "AWS CodeDeploy",
                "check": true
            },
            {
                "answer": "AWS CloudFormation",
                "check": false
            },
            {
                "answer": "AWS CodeCommit",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>AWS CodeDeploy</strong>AWS CodeDeploy is a service that automates code deployments to any instance, including Amazon EC2 instances and instances running on-premises.\n AWS CodeDeploy makes it easier for you to rapidly release new features, helps you avoid downtime during deployment, and handles the complexity of updating your applications.\n You can use AWS CodeDeploy to automate deployments, eliminating the need for error-prone manual operations, and the service scales with your infrastructure so you can easily deploy to one instance or thousands.\n",
            "incorrect": "<strong>AWS CodeCommit</strong> - AWS CodeCommit is a fully-managed source control service that hosts secure Git-based repositories.\n It makes it easy for teams to collaborate on code in a secure and highly scalable ecosystem.\n CodeCommit eliminates the need to operate your own source control system or worry about scaling its infrastructure.\n It cannot be used to automate code deployment.\n<strong>AWS CloudFormation</strong> - AWS CloudFormation allows you to use programming languages or a simple text file to model and provision, in an automated and secure manner, all the resources needed for your applications across all regions and accounts.\n It cannot be used to automate code deployment.\n<strong>AWS CodePipeline</strong> - AWS CodePipeline is a continuous delivery service that enables you to model, visualize, and automate the steps required to release your software.\n With AWS CodePipeline, you model the full release process for building your code, deploying to pre-production environments, testing your application and releasing it to production.\nAWS CodePipeline integrates with AWS services such as AWS CodeCommit, Amazon S3, AWS CodeBuild, AWS CodeDeploy, AWS Elastic Beanstalk, AWS CloudFormation, AWS OpsWorks, Amazon ECS, and AWS Lambda.\n To further elucidate, CodePipeline cannot by itself deploy the code, it can integrate with CodeDeploy for the actual deployment.\nReference:",
            "reference": "https://aws.amazon.com/codedeploy/"
        }
    },
    {
        "id": 43,
        "questions": [
            "An AWS user is trying to launch an Amazon Elastic Compute Cloud (Amazon EC2) instance in a given region. What is the region-specific constraint that the Amazon Machine Image (AMI) must meet so that it can be used for this Amazon Elastic Compute Cloud (Amazon EC2) instance?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "You must use an Amazon Machine Image (AMI) from the same region as that of the Amazon EC2 instance. The region of the Amazon Machine Image (AMI) has no bearing on the performance of the Amazon EC2 instance",
                "check": true
            },
            {
                "answer": "You can use an Amazon Machine Image (AMI) from a different region, but it degrades the performance of the Amazon EC2 instance",
                "check": false
            },
            {
                "answer": "An Amazon Machine Image (AMI) is a global entity, so the region is not applicable",
                "check": false
            },
            {
                "answer": "You should use an Amazon Machine Image (AMI) from the same region, as it improves the performance of the Amazon EC2 instance",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>You must use an Amazon Machine Image (AMI) from the same region as that of the Amazon EC2 instance.\n The region of the Amazon Machine Image (AMI) has no bearing on the performance of the Amazon EC2 instance</strong>An Amazon Machine Image (AMI) provides the information required to launch an instance.\n You must specify an Amazon Machine Image (AMI) when you launch an instance.\n You can launch multiple instances from a single AMI when you need multiple instances with the same configuration.\nThe Amazon Machine Image (AMI) must be in the same region as that of the Amazon EC2 instance to be launched.\n If the Amazon Machine Image (AMI) exists in a different region, you can copy that Amazon Machine Image (AMI) to the region where you want to launch the EC2 instance.\n The region of Amazon Machine Image (AMI) has no bearing on the performance of the Amazon EC2 instance.\n",
            "incorrect": "<strong>You can use an Amazon Machine Image (AMI) from a different region, but it degrades the performance of the Amazon EC2 instance</strong><strong>You should use an Amazon Machine Image (AMI) from the same region, as it improves the performance of the Amazon EC2 instance</strong><strong>An Amazon Machine Image (AMI) is a global entity, so the region is not applicable</strong>These three options contradict the details provided earlier in the explanation, so these options are incorrect.\nReference:",
            "reference": "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html"
        }
    },
    {
        "id": 44,
        "questions": [
            "Which option is a common stakeholder role for the AWS Cloud Adoption Framework (AWS CAF) platform perspective? (Select two)"
        ],
        "single_choice": false,
        "answers": [
            {
                "answer": "Chief Technology Officer (CTO)",
                "check": true
            },
            {
                "answer": "Chief Data Officer (CDO)",
                "check": false
            },
            {
                "answer": "Chief Product Officer (CPO)",
                "check": false
            },
            {
                "answer": "Chief Information Officer (CIO)",
                "check": false
            },
            {
                "answer": "Engineer",
                "check": true
            }
        ],
        "explanation": {
            "correct": "<strong>Engineer</strong><strong>Chief Technology Officer (CTO)</strong>The AWS Cloud Adoption Framework (AWS CAF) leverages AWS experience and best practices to help you digitally transform and accelerate your business outcomes through innovative use of AWS.\n AWS CAF identifies specific organizational capabilities that underpin successful cloud transformations.\n These capabilities provide best practice guidance that helps you improve your cloud readiness.\n AWS CAF groups its capabilities in six perspectives: Business, People, Governance, Platform, Security, and Operations.\nThe platform perspective focuses on accelerating the delivery of your cloud workloads via an enterprise-grade, scalable, hybrid cloud environment.\n It comprises seven capabilities shown in the following figure.\n Common stakeholders include Chief Technology Officer (CTO), technology leaders, architects, and engineers.\n",
            "incorrect": "<strong>Chief Product Officer (CPO)</strong><strong>Chief Data Officer (CDO)</strong><strong>Chief Information Officer (CIO)</strong>These three options contradict the explanation provided above, so these options are incorrect.\nReferences:",
            "reference": "https://d1.awsstatic.com/whitepapers/aws-caf-ebook.pdf"
        }
    },
    {
        "id": 45,
        "questions": [
            "A financial services company wants to ensure that its AWS account activity meets the governance, compliance and auditing norms. As a Cloud Practitioner, which AWS service would you recommend for this use-case?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "Amazon CloudWatch",
                "check": false
            },
            {
                "answer": "AWS Config",
                "check": false
            },
            {
                "answer": "AWS Trusted Advisor",
                "check": false
            },
            {
                "answer": "AWS CloudTrail",
                "check": true
            }
        ],
        "explanation": {
            "correct": "<strong>AWS CloudTrail</strong>You can use CloudTrail to log, monitor and retain account activity related to actions across your AWS infrastructure.\n CloudTrail provides an event history of your AWS account activity, including actions taken through the AWS Management Console, AWS SDKs, command-line tools, and other AWS services.\n",
            "incorrect": "<strong>AWS Config</strong> - AWS Config is a service that enables you to assess, audit, and evaluate the configurations of your AWS resources.\n Config continuously monitors and records your AWS resource configurations and allows you to automate the evaluation of recorded configurations against desired configurations.\n<strong>Amazon CloudWatch</strong> - Amazon CloudWatch is a monitoring and observability service built for DevOps engineers, developers, site reliability engineers (SREs), and IT managers.\n CloudWatch provides data and actionable insights to monitor applications, respond to system-wide performance changes, optimize resource utilization, and get a unified view of operational health.\n This is an excellent service for building Resilient systems.\n<strong>AWS Trusted Advisor</strong> - AWS Trusted Advisor is an online tool that provides you real-time guidance to help you provision your resources following AWS best practices on cost optimization, security, fault tolerance, service limits and performance improvement.\nExam Alert:You may see use-cases asking you to select one of CloudWatch vs CloudTrail vs Config.\n Just remember this thumb rule -Think resource performance monitoring, events, and alerts; think CloudWatch.\nThink account-specific activity and audit; think CloudTrail.\nThink resource-specific change history, audit, and compliance; think Config.\nReference:",
            "reference": "https://aws.amazon.com/cloudtrail/"
        }
    },
    {
        "id": 46,
        "questions": [
            "An IT company wants to run a log backup process every Monday at 2 AM. The usual runtime of the process is 5 minutes. As a Cloud Practitioner, which AWS services would you recommend to build a serverless solution for this use-case? (Select two)"
        ],
        "single_choice": false,
        "answers": [
            {
                "answer": "AWS Systems Manager",
                "check": false
            },
            {
                "answer": "AWS Step Function",
                "check": false
            },
            {
                "answer": "AWS Lambda",
                "check": true
            },
            {
                "answer": "Amazon Elastic Compute Cloud (Amazon EC2)",
                "check": false
            },
            {
                "answer": "Amazon Eventbridge",
                "check": true
            }
        ],
        "explanation": {
            "correct": "<strong>Amazon Eventbridge</strong> - Amazon EventBridge is a service that provides real-time access to changes in data in AWS services, your own applications, and software as a service (SaaS) applications without writing code.\n Amazon EventBridge Scheduler is a serverless task scheduler that simplifies creating, executing, and managing millions of schedules across AWS services without provisioning or managing underlying infrastructure.\n<strong>AWS Lambda</strong> - AWS Lambda lets you run code without provisioning or managing servers.\n You pay only for the compute time you consume.\n The lambda has a maximum execution time of 15 minutes, so it can be used to run this log backup process.\nTo build the solution for the given use-case, you can leverage the Amazon EventBridge Scheduler to trigger on a schedule.\n You can then set the Lambda as the target for this rule.\n",
            "incorrect": "<strong>AWS Systems Manager</strong> - AWS Systems Manager gives you visibility and control of your infrastructure on AWS.\n Systems Manager provides a unified user interface so you can view operational data from multiple AWS services and allows you to automate operational tasks across your AWS resources.\n With Systems Manager, you can group resources, like Amazon EC2 instances, Amazon S3 buckets, or Amazon RDS instances, by application, view operational data for monitoring and troubleshooting, and take action on your groups of resources.\n Secrets Manager cannot be used to run a process on a schedule.\n<strong>Amazon Elastic Compute Cloud (Amazon EC2)</strong> - Amazon Elastic Compute Cloud (Amazon EC2) is a web service that provides secure, resizable compute capacity in the cloud with support for per-second billing.\n It is the easiest way to provision servers on AWS Cloud and access the underlying OS.\n As the company wants a serverless solution, so this option is ruled out.\n<strong>AWS Step Function</strong> - AWS Step Function lets you coordinate multiple AWS services into serverless workflows.\n You can design and run workflows that stitch together services such as AWS Lambda, AWS Glue and Amazon SageMaker.\n Step Function cannot be used to run a process on a schedule.\nReference:",
            "reference": "https://aws.amazon.com/eventbridge/"
        }
    },
    {
        "id": 47,
        "questions": [
            "A multi-national corporation wants to get expert professional advice on migrating to AWS and managing their applications on AWS Cloud. Which of the following entities would you recommend for this engagement?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "APN Consulting Partner",
                "check": true
            },
            {
                "answer": "AWS Trusted Advisor",
                "check": false
            },
            {
                "answer": "Concierge Support Team",
                "check": false
            },
            {
                "answer": "APN Technology Partner",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>APN Consulting Partner</strong>The AWS Partner Network (APN) is the global partner program for technology and consulting businesses that leverage Amazon Web Services to build solutions and services for customers.\nAPN Consulting Partners are professional services firms that help customers of all types and sizes design, architect, build, migrate, and manage their workloads and applications on AWS, accelerating their migration to AWS cloud.\n",
            "incorrect": "<strong>APN Technology Partner</strong> - APN Technology Partners provide hardware, connectivity services, or software solutions that are either hosted on or integrated with, the AWS Cloud.\n APN Technology Partners cannot help in migrating to AWS and managing applications on AWS Cloud.\n<strong>AWS Trusted Advisor</strong> - AWS Trusted Advisor is an online tool that provides you real-time guidance to help you provision your resources following AWS best practices on cost optimization, security, fault tolerance, service limits, and performance improvement.\n Whether establishing new workflows, developing applications, or as part of ongoing improvement, recommendations provided by Trusted Advisor regularly help keep your solutions provisioned optimally.\n All AWS customers get access to the seven core Trusted Advisor checks to help increase the security and performance of the AWS environment.\n Trusted Advisor cannot be used to migrate to AWS and manage applications on AWS Cloud.\n<strong>Concierge Support Team</strong> - The Concierge Support Team are AWS billing and account experts that specialize in working with enterprise accounts.\n They will quickly and efficiently assist you with your billing and account inquiries.\n The Concierge Support Team is only available for the Enterprise Support plan.\n Concierge Support Team cannot help in migrating to AWS and managing applications on AWS Cloud.\nReference:",
            "reference": "https://aws.amazon.com/partners/"
        }
    },
    {
        "id": 48,
        "questions": [
            "AWS Marketplace facilitates which of the following use-cases? (Select two)"
        ],
        "single_choice": false,
        "answers": [
            {
                "answer": "Raise request for purchasing AWS Direct Connect connection",
                "check": false
            },
            {
                "answer": "Buy Amazon EC2 Standard Reserved Instances (RI)",
                "check": false
            },
            {
                "answer": "Sell Software as a Service (SaaS) solutions to AWS customers",
                "check": true
            },
            {
                "answer": "AWS customer can buy software that has been bundled into customized Amazon Machine Image (AMIs) by the AWS Marketplace sellers",
                "check": true
            },
            {
                "answer": "Purchase compliance documents from third-party vendors",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>Sell Software as a Service (SaaS) solutions to AWS customers</strong><strong>AWS customer can buy software that has been bundled into customized Amazon Machine Image (AMIs) by the AWS Marketplace sellers</strong>AWS Marketplace is a digital catalog with thousands of software listings from independent software vendors that make it easy to find, test, buy, and deploy software that runs on AWS.\n The AWS Marketplace enables qualified partners to market and sell their software to AWS Customers.\nAWS Marketplace offers two ways for sellers to deliver software to customers: Amazon Machine Image (AMI) and Software as a Service (SaaS).\nAmazon Machine Image (AMI): Offering an AMI is the preferred option for listing products in AWS Marketplace.\n Partners have the option for free or paid products.\n Partners can offer paid products charged by the hour or month.\n Bring-Your-Own-License (BYOL) is also available and enables customers with existing software licenses to easily migrate to AWS.\nSoftware as a Service (SaaS): If you offer a SaaS solution running on AWS (and are unable to build your product into an AMI) the SaaS listing offers our partners a way to market their software to customers.\n",
            "incorrect": "<strong>Purchase compliance documents from third-party vendors</strong> - There is no third party vendor for providing compliance documents.\n AWS Artifact is your go-to, central resource for compliance-related information that matters to you.\n It provides on-demand access to AWS’ security and compliance reports and select online agreements.\nReferences:",
            "reference": "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ri-market-concepts-buying.html#ri-queued-purchase"
        }
    },
    {
        "id": 49,
        "questions": [
            "Which AWS service can help you analyze your infrastructure to identify unattached or underutilized Amazon EBS Elastic Volumes?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "AWS Trusted Advisor",
                "check": true
            },
            {
                "answer": "AWS Config",
                "check": false
            },
            {
                "answer": "Amazon CloudWatch",
                "check": false
            },
            {
                "answer": "Amazon Inspector",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>AWS Trusted Advisor</strong>AWS Trusted Advisor is an online tool that provides real-time guidance to help provision your resources following AWS best practices.\n Whether establishing new workflows, developing applications, or as part of ongoing improvement, recommendations provided by Trusted Advisor regularly help keep your solutions provisioned optimally.\n AWS Trusted Advisor analyzes your AWS environment and provides best practice recommendations in five categories: Cost Optimization, Performance, Security, Fault Tolerance, Service Limits.\nAWS Trusted Advisor can check Amazon Elastic Block Store (Amazon EBS) volume configurations and warns when volumes appear to be underused.\n Charges begin when a volume is created.\n If a volume remains unattached or has very low write activity (excluding boot volumes) for a period of time, the volume is probably not being used.\n",
            "incorrect": "<strong>AWS Config</strong> - AWS Config is a service that enables you to assess, audit, and evaluate the configurations of your AWS resources.\n Config continuously monitors and records your AWS resource configurations and allows you to automate the evaluation of recorded configurations against desired configurations.\n Think resource-specific change history, audit, and compliance; think Config.\n Its a configuration tracking service and not an infrastructure tracking service.\n<strong>Amazon CloudWatch</strong> - Amazon CloudWatch is a monitoring and observability service built for DevOps engineers, developers, site reliability engineers (SREs), and IT managers.\n CloudWatch provides data and actionable insights to monitor applications, respond to system-wide performance changes, optimize resource utilization, and get a unified view of operational health.\n\nAmazon EBS emits notifications based on Amazon CloudWatch Events for a variety of volume, snapshot, and encryption status changes.\n With CloudWatch Events, you can establish rules that trigger programmatic actions in response to a change in volume, snapshot, or encryption key state (though not for underutilized volume usage).\n<strong>Amazon Inspector</strong> - Amazon Inspector is an automated security assessment service that helps improve the security and compliance of applications deployed on your Amazon EC2 instances.\n Amazon Inspector automatically assesses applications for exposure, vulnerabilities, and deviations from best practices.\n Its a security assessment service and not an infrastructure tracking service.\nReferences:",
            "reference": "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-cloud-watch-events.html"
        }
    },
    {
        "id": 50,
        "questions": [
            "Which of the following statements is the MOST accurate when describing AWS Elastic Beanstalk?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "It is an Infrastructure as a Service (IaaS) that allows you to deploy and scale web applications and services",
                "check": false
            },
            {
                "answer": "It is a Platform as a Service (PaaS) that allows you to deploy and scale web applications and services",
                "check": true
            },
            {
                "answer": "It is a Platform as a Service (PaaS) that allows you to model and provision resources needed for an application",
                "check": false
            },
            {
                "answer": "It is an Infrastructure as Code (IaC) that allows you to model and provision resources needed for an application",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>It is a Platform as a Service (PaaS) that allows you to deploy and scale web applications and services</strong>AWS Elastic Beanstalk makes it even easier for developers to quickly deploy and manage applications in the AWS Cloud.\n Developers simply upload their applications, and AWS Elastic Beanstalk automatically handles the deployment details of capacity provisioning, load balancing, auto-scaling, and application health monitoring.\nIt is a Platform as a Service (PaaS) as you only manage the applications and the data.\n",
            "incorrect": "<strong>It is an Infrastructure as Code (IaC) that allows you to model and provision resources needed for an application</strong> - This is the definition of AWS CloudFormation.\n AWS CloudFormation gives developers and systems administrators an easy way to create and manage a collection of related AWS resources, provisioning and updating them in an orderly and predictable fashion.\n You can use the AWS CloudFormation sample templates or create your own templates to describe your AWS resources, and any associated dependencies or runtime parameters, required to run your application.\n<strong>It is a Platform as a Service (PaaS) that allows you to model and provision resources needed for an application</strong> - AWS Elastic Beanstalk is a Platform as a Service (PaaS).\n However, the service that allows you to model and provision resources needed for an application is AWS CloudFormation.\n<strong>It is an Infrastructure as a Service (IaaS) that allows you to deploy and scale web applications and services</strong> - AWS Elastic Beanstalk allows you to deploy and scale web applications and services, but it is not an Infrastructure as a Service (IaaS).\n With AWS Elastic Beanstalk, you do not manage the runtime, the middleware, and the operating system.\nReference:",
            "reference": "https://aws.amazon.com/elasticbeanstalk/"
        }
    },
    {
        "id": 51,
        "questions": [
            "AWS Compute Optimizer delivers recommendations for which of the following AWS resources? (Select two)"
        ],
        "single_choice": false,
        "answers": [
            {
                "answer": "Amazon Elastic Compute Cloud (Amazon EC2) instances, Amazon Elastic File System (Amazon EFS)",
                "check": false
            },
            {
                "answer": "AWS Lambda functions, Amazon Simple Storage Service (Amazon S3)",
                "check": false
            },
            {
                "answer": "Amazon Elastic File System (Amazon EFS), AWS Lambda functions",
                "check": false
            },
            {
                "answer": "Amazon Elastic Compute Cloud (Amazon EC2) instances, Amazon EC2 Auto Scaling groups",
                "check": true
            },
            {
                "answer": "Amazon Elastic Block Store (Amazon EBS), AWS Lambda functions",
                "check": true
            }
        ],
        "explanation": {
            "correct": "<strong>Amazon Elastic Compute Cloud (Amazon EC2) instances, Amazon EC2 Auto Scaling groups</strong><strong>Amazon Elastic Block Store (Amazon EBS), AWS Lambda functions</strong>AWS Compute Optimizer helps you identify the optimal AWS resource configurations, such as Amazon EC2 instance types, Amazon EBS volume configurations, and AWS Lambda function memory sizes, using machine learning to analyze historical utilization metrics.\n AWS Compute Optimizer delivers recommendations for selected types of EC2 instances, EC2 Auto Scaling groups, Amazon EBS volumes, and AWS Lambda functions.\nAWS Compute Optimizer calculates an individual performance risk score for each resource dimension of the recommended instance, including CPU, memory, EBS throughput, EBS IOPS, disk throughput, disk throughput, network throughput, and network packets per second (PPS).\nAWS Compute Optimizer provides EC2 instance type and size recommendations for EC2 Auto Scaling groups with a fixed group size, meaning desired, minimum, and maximum are all set to the same value and have no scaling policy attached.\nAWS Compute Optimizer supports IOPS and throughput recommendations for General Purpose (SSD) (gp3) volumes and IOPS recommendations for Provisioned IOPS (io1 and io2) volumes.\nAWS Compute Optimizer helps you optimize two categories of Lambda functions.\n The first category includes Lambda functions that may be over-provisioned in memory sizes.\n The second category includes compute-intensive Lambda functions that may benefit from additional CPU power.\n",
            "incorrect": "<strong>Amazon Elastic Compute Cloud (Amazon EC2) instances, Amazon Elastic File System (Amazon EFS)</strong><strong>Amazon Elastic File System (Amazon EFS), AWS Lambda functions</strong><strong>AWS Lambda functions, Amazon Simple Storage Service (Amazon S3)</strong>AWS Compute Optimizer does not provide optimization recommendations for S3 and EFS, so these options are incorrect.\nReference:",
            "reference": "https://aws.amazon.com/compute-optimizer/faqs/"
        }
    },
    {
        "id": 52,
        "questions": [
            "Which of the following are correct statements regarding the AWS Shared Responsibility Model? (Select two)"
        ],
        "single_choice": false,
        "answers": [
            {
                "answer": "For abstracted services like Amazon S3, AWS operates the infrastructure layer, the operating system, and platforms",
                "check": true
            },
            {
                "answer": "Configuration Management is the responsibility of the customer",
                "check": false
            },
            {
                "answer": "AWS is responsible for training AWS and customer employees on AWS products and services",
                "check": false
            },
            {
                "answer": "AWS is responsible for Security 'of' the Cloud",
                "check": true
            },
            {
                "answer": "For a service like Amazon EC2, that falls under Infrastructure as a Service (IaaS), AWS is responsible for maintaining guest operating system",
                "check": false
            }
        ],
        "explanation": {
            "correct": "Security and Compliance is a shared responsibility between AWS and the customer.\n This shared model can help relieve the customer’s operational burden as AWS operates, manages and controls the components from the host operating system and virtualization layer down to the physical security of the facilities in which the service operates.\n<strong>AWS is responsible for Security 'of' the Cloud</strong>AWS is responsible for protecting the infrastructure that runs all of the services offered in the AWS Cloud.\n This infrastructure is composed of the hardware, software, networking, and facilities that run AWS Cloud services.\n<strong>For abstracted services like Amazon S3, AWS operates the infrastructure layer, the operating system, and platforms</strong>For abstracted services, such as Amazon S3 and Amazon DynamoDB, AWS operates the infrastructure layer, the operating system, and platforms, and customers access the endpoints to store and retrieve data.\n",
            "incorrect": "<strong>For a service like Amazon EC2, that falls under Infrastructure as a Service (IaaS), AWS is responsible for maintaining guest operating system</strong> - A service such as Amazon Elastic Compute Cloud (Amazon EC2) is categorized as Infrastructure as a Service (IaaS) and, as such, requires the customer to perform all of the necessary security configuration and management tasks.\n Customers are responsible for the management of the guest operating system (including updates and security patches), any application software or utilities installed by the customer on the instances, and the configuration of the AWS-provided firewall (called a security group) on each instance.\n<strong>Configuration Management is the responsibility of the customer</strong> - Configuration management is a shared responsibility.\n AWS maintains the configuration of its infrastructure devices, but a customer is responsible for configuring their own guest operating systems, databases, and applications.\n<strong>AWS is responsible for training AWS and customer employees on AWS products and services</strong> - Awareness &amp; Training is also a shared responsibility.\n AWS trains AWS employees, but a customer must train their own employees.\nReference:",
            "reference": "https://aws.amazon.com/compliance/shared-responsibility-model/"
        }
    },
    {
        "id": 53,
        "questions": [
            "Which of the following Amazon S3 storage classes takes the most time to retrieve data (also known as first byte latency)?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "Amazon S3 Glacier Deep Archive",
                "check": true
            },
            {
                "answer": "Amazon S3 Glacier Flexible Retrieval",
                "check": false
            },
            {
                "answer": "Amazon S3 Standard",
                "check": false
            },
            {
                "answer": "Amazon S3 Intelligent-Tiering",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>Amazon S3 Glacier Deep Archive</strong>Amazon S3 Glacier Deep Archive is Amazon S3’s lowest-cost storage class and supports long-term retention and digital preservation for data that may be accessed once or twice in a year.\n It is designed for customers — particularly those in highly-regulated industries, such as the Financial Services, Healthcare, and Public Sectors — that retain data sets for 7-10 years or longer to meet regulatory compliance requirements.\n Amazon S3 Glacier Deep Archive can also be used for backup and disaster recovery use cases.\n It has a retrieval time (first byte latency) of 12 to 48 hours.\n",
            "incorrect": "<strong>Amazon S3 Standard</strong> - Amazon S3 Standard offers high durability, availability, and performance object storage for frequently accessed data.\n Amazon S3 Standard has a retrieval time (first byte latency) of milliseconds.\n<strong>Amazon S3 Intelligent-Tiering</strong> - The Amazon S3 Intelligent-Tiering storage class is designed to optimize costs by automatically moving data to the most cost-effective access tier, without performance impact or operational overhead.\n It works by storing objects in two access tiers: one tier that is optimized for frequent access and another lower-cost tier that is optimized for infrequent access.\n Amazon S3 Intelligent-Tiering has a retrieval time (first byte latency) of milliseconds.\n<strong>Amazon S3 Glacier Flexible Retrieval</strong> - Amazon S3 Glacier Flexible Retrieval delivers low-cost storage, up to 10% lower cost (than Amazon S3 Glacier Instant Retrieval), for archive data that is accessed 1—2 times per year and is retrieved asynchronously.\n For archive data that does not require immediate access but needs the flexibility to retrieve large sets of data at no cost, such as backup or disaster recovery use cases, Amazon S3 Glacier Flexible Retrieval (formerly Amazon S3 Glacier) is the ideal storage class.\nReference:",
            "reference": "https://aws.amazon.com/s3/storage-classes/"
        }
    },
    {
        "id": 54,
        "questions": [
            "An organization deploys its IT infrastructure in a combination of its on-premises data center along with AWS Cloud. How would you categorize this deployment model?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "Private deployment",
                "check": false
            },
            {
                "answer": "Mixed deployment",
                "check": false
            },
            {
                "answer": "Cloud deployment",
                "check": false
            },
            {
                "answer": "Hybrid deployment",
                "check": true
            }
        ],
        "explanation": {
            "correct": "<strong>Hybrid deployment</strong>A hybrid deployment is a way to connect your on-premises infrastructure to the cloud.\n The most common method of hybrid deployment is between the cloud and existing on-premises infrastructure to extend an organization's infrastructure into the cloud while connecting cloud resources to internal systems.\n",
            "incorrect": "<strong>Cloud deployment</strong> - For this type of deployment, a cloud-based application is fully deployed in the cloud, and all parts of the application run in the cloud.\n Applications in the cloud have either been created in the cloud or have been migrated from an existing infrastructure to take advantage of the benefits of cloud computing.\n<strong>Private deployment</strong> - For this deployment model, resources are deployed on-premises using virtualization technologies.\n On-premises deployment does not provide many of the benefits of cloud computing but is sometimes sought for its ability to provide dedicated resources.\n<strong>Mixed deployment</strong> - This is a made-up option and has been added as a distractor.\nReferences:",
            "reference": "https://aws.amazon.com/hybrid/"
        }
    },
    {
        "id": 55,
        "questions": [
            "A cyber-security agency uses AWS Cloud and wants to carry out security assessments on its own AWS infrastructure without any prior approval from AWS. Which of the following describes/facilitates this practice?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "Amazon Inspector",
                "check": false
            },
            {
                "answer": "AWS Secrets Manager",
                "check": false
            },
            {
                "answer": "Penetration Testing",
                "check": true
            },
            {
                "answer": "Network Stress Testing",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>Penetration Testing</strong>AWS customers can carry out security assessments or penetration tests against their AWS infrastructure without prior approval for few common AWS services.\n Customers are not permitted to conduct any security assessments of AWS infrastructure, or the AWS services themselves.\n",
            "incorrect": "<strong>Network Stress Testing</strong> - AWS considers \"network stress test\" to be when a test sends a large volume of legitimate or test traffic to a specific intended target application.\n The endpoint and infrastructure are expected to be able to handle this traffic.\n<strong>Amazon Inspector</strong> - Amazon Inspector is an automated, security assessment service that helps you check for unintended network accessibility of your Amazon EC2 instances and for vulnerabilities on those Amazon EC2 instances.\n Amazon Inspector assessments are offered to you as pre-defined rules packages mapped to common security best practices and vulnerability definitions.\n<strong>AWS Secrets Manager</strong> - AWS Secrets Manager helps you protect secrets needed to access your applications, services, and IT resources.\n The service enables you to easily rotate, manage, and retrieve database credentials, API keys, and other secrets throughout their lifecycle.\n Users and applications retrieve secrets with a call to AWS Secrets Manager APIs, eliminating the need to hardcode sensitive information in plain text.\nReference:",
            "reference": "https://aws.amazon.com/security/penetration-testing/"
        }
    },
    {
        "id": 56,
        "questions": [
            "Which of the following are the advantages of using the AWS Cloud? (Select TWO)"
        ],
        "single_choice": false,
        "answers": [
            {
                "answer": "Increase speed and agility",
                "check": true
            },
            {
                "answer": "Stop guessing about capacity",
                "check": true
            },
            {
                "answer": "Limited scaling",
                "check": false
            },
            {
                "answer": "Trade operational expense for capital expense",
                "check": false
            },
            {
                "answer": "AWS is responsible for security in the cloud",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>Increase speed and agility</strong><strong>Stop guessing about capacity</strong>Exam Alert:Please check out the following six advantages of Cloud Computing.\n You would certainly be asked questions on the advantages of Cloud Computing compared to a traditional on-premises setup:",
            "incorrect": "<strong>Limited scaling</strong> - Scaling is not limited in the cloud.\n You can access as much or as little capacity as you need, and scale up and down as required with only a few minutes’ notice.\n<strong>AWS is responsible for security in the cloud</strong> - AWS is responsible for the security OF the cloud, which means AWS is responsible for protecting the infrastructure that runs all the services offered in the AWS Cloud.\n<strong>Trade operational expense for capital expense</strong> - In the cloud, you trade capital expense (CAPEX) for the operational expense (OPEX).\n Instead of having to invest heavily in data centers and servers before you know how you’re going to use them, you can pay only when you consume computing resources, and pay only for how much you consume.\nReference:",
            "reference": "https://docs.aws.amazon.com/whitepapers/latest/aws-overview/six-advantages-of-cloud-computing.html"
        }
    },
    {
        "id": 57,
        "questions": [
            "A data analytics company is running a proprietary batch analytics application on AWS and wants to use a storage service which would be accessed by hundreds of EC2 instances simultaneously to append data to existing files. As a Cloud Practitioner, which AWS service would you suggest for this use-case?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "Instance Store",
                "check": false
            },
            {
                "answer": "Amazon Simple Storage Service (Amazon S3)",
                "check": false
            },
            {
                "answer": "Amazon Elastic File System (Amazon EFS)",
                "check": true
            },
            {
                "answer": "Amazon Elastic Block Store (Amazon EBS)",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>Amazon Elastic File System (Amazon EFS)</strong>Amazon EFS is a file storage service for use with Amazon EC2.\n Amazon EFS provides a file system interface, file system access semantics, and concurrently-accessible storage for up to thousands of Amazon EC2 instances.\n Amazon EFS uses the Network File System protocol.\n",
            "incorrect": "<strong>Amazon Elastic Block Store (Amazon EBS)</strong> - Amazon Elastic Block Store (EBS) is an easy to use, high-performance block storage service designed for use with Amazon Elastic Compute Cloud (EC2) for both throughput and transaction-intensive workloads at any scale.\n EBS volumes cannot be accessed simultaneously by multiple EC2 instances, so this option is incorrect.\n<strong>Instance Store</strong> - An instance store provides temporary block-level storage for your instance.\n This storage is located on disks that are physically attached to the host computer.\n Instance Store volumes cannot be accessed simultaneously by multiple EC2 instances, so this option is incorrect.\n<strong>Amazon Simple Storage Service (Amazon S3)</strong> - Amazon Simple Storage Service (Amazon S3) is an object storage service that offers industry-leading scalability, data availability, security, and performance.\n S3 is object storage and it does not support file append operations, so this option is incorrect.\nReference:",
            "reference": "https://aws.amazon.com/efs/"
        }
    },
    {
        "id": 58,
        "questions": [
            "A company would like to optimize Amazon Elastic Compute Cloud (Amazon EC2) costs. Which of the following actions can help with this task? (Select TWO)"
        ],
        "single_choice": false,
        "answers": [
            {
                "answer": "Build its own servers",
                "check": false
            },
            {
                "answer": "Set up Auto Scaling groups to align the number of instances with the demand",
                "check": true
            },
            {
                "answer": "Vertically scale the EC2 instances",
                "check": false
            },
            {
                "answer": "Opt for a higher AWS Support plan",
                "check": false
            },
            {
                "answer": "Purchase Amazon EC2 Reserved instances (RIs)",
                "check": true
            }
        ],
        "explanation": {
            "correct": "<strong>Set up Auto Scaling groups to align the number of instances with the demand</strong><strong>Purchase Amazon EC2 Reserved instances (RIs)</strong>An Auto Scaling group contains a collection of Amazon EC2 instances that are treated as a logical grouping for automatic scaling and management.\n You can adjust its size to meet demand, either manually or by using automatic scaling.\nAWS Auto Scaling can help you optimize your utilization and cost efficiencies when consuming AWS services so you only pay for the resources you need.\nAmazon EC2 Reserved Instances (RI) provide a significant discount (up to 72%) compared to On-Demand pricing and provide a capacity reservation when used in a specific Availability Zone (AZ).\n",
            "incorrect": "<strong>Vertically scale the EC2 instances</strong> - Vertically scaling EC2 instances (increasing one computer performance by adding CPUs, memory, and storage) is limited and is way more expensive than scaling horizontally (adding more computers to the system).\n<strong>Opt for a higher AWS Support plan</strong> - The AWS Support plans do not help with EC2 costs.\n<strong>Build its own servers</strong> - Building your own servers is more expensive than using EC2 instances in the cloud.\n You're more likely to spend more money than saving money.\nReferences:",
            "reference": "https://aws.amazon.com/autoscaling/"
        }
    },
    {
        "id": 59,
        "questions": [
            "AWS Organizations provides which of the following benefits? (Select two)"
        ],
        "single_choice": false,
        "answers": [
            {
                "answer": "Deploy patches on Amazon EC2 instances across the member AWS accounts",
                "check": false
            },
            {
                "answer": "Check vulnerabilities on Amazon EC2 instances across the member AWS accounts",
                "check": false
            },
            {
                "answer": "Provision Amazon EC2 Spot instances across the member AWS accounts",
                "check": false
            },
            {
                "answer": "Volume discounts for Amazon EC2 and Amazon S3 aggregated across the member AWS accounts",
                "check": true
            },
            {
                "answer": "Share the reserved Amazon EC2 instances amongst the member AWS accounts",
                "check": true
            }
        ],
        "explanation": {
            "correct": "<strong>Volume discounts for Amazon EC2 and Amazon S3 aggregated across the member AWS accounts</strong><strong>Share the reserved Amazon EC2 instances amongst the member AWS accounts</strong>AWS Organizations helps you to centrally manage billing; control access, compliance, and security; and share resources such as reserved Amazon EC2 instances across your AWS accounts.\nUsing AWS Organizations, you can automate account creation, create groups of accounts to reflect your business needs, and apply policies for these groups for governance.\n You can also simplify billing by setting up a single payment method for all of your AWS accounts.\n AWS Organizations is available to all AWS customers at no additional charge.\nYou can use AWS Organizations to set up a single payment method for all the AWS accounts in your organization through consolidated billing.\n With consolidated billing, you can see a combined view of charges incurred by all your accounts, as well as take advantage of pricing benefits from aggregated usage, such as volume discounts for Amazon EC2 and Amazon S3.\n",
            "incorrect": "<strong>Check vulnerabilities on Amazon EC2 instances across the member AWS accounts</strong><strong>Deploy patches on Amazon EC2 instances across the member AWS accounts</strong><strong>Provision Amazon EC2 Spot instances across the member AWS accounts</strong>These three options contradict the details provided earlier in the explanation, so these options are incorrect.\nReference:",
            "reference": "https://aws.amazon.com/organizations/"
        }
    },
    {
        "id": 60,
        "questions": [
            "What is the primary benefit of deploying an Amazon RDS Multi-AZ database with one standby?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "Amazon RDS Multi-AZ improves database performance for read-heavy workloads",
                "check": false
            },
            {
                "answer": "Amazon RDS Multi-AZ protects the database from a regional failure",
                "check": false
            },
            {
                "answer": "Amazon RDS Multi-AZ reduces database usage costs",
                "check": false
            },
            {
                "answer": "Amazon RDS Multi-AZ enhances database availability",
                "check": true
            }
        ],
        "explanation": {
            "correct": "<strong>Amazon RDS Multi-AZ enhances database availability</strong>Amazon RDS Multi-AZ deployments provide enhanced availability and durability forAmazon Relational Database Service (Amazon RDS) instances, making them a natural fit for production database workloads.\n When you provision an Amazon RDS Multi-AZ Instance with one standby, Amazon RDS automatically creates a primary DB Instance and synchronously replicates the data to a standby instance in a different Availability Zone (AZ).\nIn case of an infrastructure failure, Amazon RDS performs an automatic failover to the standby so that you can resume database operations as soon as the failover is complete.\nExam Alert:",
            "incorrect": "<strong>Amazon RDS Multi-AZ improves database performance for read-heavy workloads</strong> - Amazon RDS Multi-AZ with one standby does not allow read operations from the standby.\n Read Replicas allow you to create read-only copies that are synchronized with your master database.\n Read Replicas are used for improved read performance.\n Therefore, this option is incorrect.\n<strong>Amazon RDS Multi-AZ protects the database from a regional failure</strong> - You need to use RDS in Multi-Region deployment configuration to protect from a regional failure.\n Amazon RDS Multi-AZ cannot protect from a regional failure.\n<strong>Amazon RDS Multi-AZ reduces database usage costs</strong> - Amazon RDS Multi-AZ increases the database costs compared to the standard deployment.\n So this option is incorrect.\nReference:",
            "reference": "https://aws.amazon.com/rds/features/multi-az/"
        }
    },
    {
        "id": 61,
        "questions": [
            "A financial services company wants to migrate from its on-premises data center to AWS Cloud. As a Cloud Practitioner, which AWS service would you recommend so that the company can compare the cost of running their IT infrastructure on-premises vs AWS Cloud?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "AWS Cost Explorer",
                "check": false
            },
            {
                "answer": "AWS Trusted Advisor",
                "check": false
            },
            {
                "answer": "AWS Pricing Calculator",
                "check": true
            },
            {
                "answer": "AWS Budgets",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>AWS Pricing Calculator</strong>AWS also offers a complimentary service called Migration Evaluator (Formerly TSO Logic) to create data-driven business cases for AWS Cloud planning and migration.\n",
            "incorrect": "<strong>AWS Trusted Advisor</strong> - AWS Trusted Advisor provides recommendations that help you follow AWS best practices.\n Trusted Advisor evaluates your account by using checks.\n These checks identify ways to optimize your AWS infrastructure, improve security and performance, reduce costs, and monitor service quotas.\n This service cannot be used to compare the cost of running the IT infrastructure on-premises vs AWS Cloud.\n<strong>AWS Cost Explorer</strong> - AWS Cost Explorer has an easy-to-use interface that lets you visualize, understand, and manage your AWS costs and usage over time.\n AWS Cost Explorer includes a default report that helps you visualize the costs and usage associated with your top five cost-accruing AWS services, and gives you a detailed breakdown of all services in the table view.\n The reports let you adjust the time range to view historical data going back up to twelve months to gain an understanding of your cost trends.\n AWS Cost Explorer cannot be used to compare the cost of running the IT infrastructure on-premises vs AWS Cloud.\n<strong>AWS Budgets</strong> - AWS Budgets gives the ability to set custom budgets that alert you when your costs or usage exceed (or are forecasted to exceed) your budgeted amount.\n You can also use AWS Budgets to set reservation utilization or coverage targets and receive alerts when your utilization drops below the threshold you define.\n Budgets can be created at the monthly, quarterly, or yearly level, and you can customize the start and end dates.\n You can further refine your budget to track costs associated with multiple dimensions, such as AWS service, linked account, tag, and others.\n  AWS Budgets cannot be used to compare the cost of running the IT infrastructure on-premises vs AWS Cloud.\nReference:",
            "reference": "https://aws.amazon.com/migration-evaluator/"
        }
    },
    {
        "id": 62,
        "questions": [
            "A unicorn startup is building an analytics application with support for a speech-based interface. The application will accept speech-based input from users and then convey results via speech. As a Cloud Practitioner, which solution would you recommend for the given use-case?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "Use Amazon Transcribe to convert speech to text for downstream analysis. Then use Amazon Polly to convey the text results via speech",
                "check": true
            },
            {
                "answer": "Use Amazon Polly to convert speech to text for downstream analysis. Then use Amazon Translate to convey the text results via speech",
                "check": false
            },
            {
                "answer": "Use Amazon Polly to convert speech to text for downstream analysis. Then use Amazon Transcribe to convey the text results via speech",
                "check": false
            },
            {
                "answer": "Use Amazon Translate to convert speech to text for downstream analysis. Then use Amazon Polly to convey the text results via speech",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>Use Amazon Transcribe to convert speech to text for downstream analysis.\n Then use Amazon Polly to convey the text results via speech</strong>You can use Amazon Transcribe to add speech-to-text capability to your applications.\n Amazon Transcribe uses a deep learning process called automatic speech recognition (ASR) to convert speech to text quickly and accurately.\n Amazon Transcribe can be used to transcribe customer service calls, to automate closed captioning and subtitling, and to generate metadata for media assets.\nYou can use Amazon Polly to turn text into lifelike speech thereby allowing you to create applications that talk.\n Polly's Text-to-Speech (TTS) service uses advanced deep learning technologies to synthesize natural sounding human speech.\nAmazon Translate is used for language translation.\n Amazon Translate uses neural machine translation via deep learning models to deliver more accurate and more natural-sounding translation than traditional statistical and rule-based translation algorithms.\n",
            "incorrect": "<strong>Use Amazon Polly to convert speech to text for downstream analysis.\n Then use Amazon Transcribe to convey the text results via speech</strong> - Amazon Polly cannot be used to convert speech to text, so this option is incorrect.\n<strong>Use Amazon Translate to convert speech to text for downstream analysis.\n Then use Amazon Polly to convey the text results via speech</strong> - Amazon Translate cannot convert speech to text, so this option is incorrect.\n<strong>Use Amazon Polly to convert speech to text for downstream analysis.\n Then use Amazon Translate to convey the text results via speech</strong> - Amazon Polly cannot be used to convert speech to text, so this option is incorrect.\nReferences:",
            "reference": "https://aws.amazon.com/polly/"
        }
    },
    {
        "id": 63,
        "questions": [
            "A company uses reserved EC2 instances across multiple units with each unit having its own AWS account. However, some of the units under-utilize their reserved instances while other units need more reserved instances. As a Cloud Practitioner, which of the following would you recommend as the most cost-optimal solution?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "Use AWS Cost Explorer to manage AWS accounts of all units and then share the reserved EC2 instances amongst all units",
                "check": false
            },
            {
                "answer": "Use AWS Trusted Advisor to manage AWS accounts of all units and then share the reserved EC2 instances amongst all units",
                "check": false
            },
            {
                "answer": "Use AWS Organizations to manage AWS accounts of all units and then share the reserved EC2 instances amongst all units",
                "check": true
            },
            {
                "answer": "Use AWS Systems Manager to manage AWS accounts of all units and then share the reserved EC2 instances amongst all units",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>Use AWS Organizations to manage AWS accounts of all units and then share the reserved EC2 instances amongst all units</strong>AWS Organizations helps you to centrally manage billing; control access, compliance, and security; and share resources across your AWS accounts.\n Using AWS Organizations, you can automate account creation, create groups of accounts to reflect your business needs, and apply policies for these groups for governance.\n You can also simplify billing by setting up a single payment method for all of your AWS accounts.\n AWS Organizations is available to all AWS customers at no additional charge.\n",
            "incorrect": "<strong>Use AWS Trusted Advisor to manage AWS accounts of all units and then share the reserved EC2 instances amongst all units</strong> - AWS Trusted Advisor is an online tool that provides you real-time guidance to help you provision your resources following AWS best practices on cost optimization, security, fault tolerance, service limits, and performance improvement.\n You cannot use Trusted Advisor to share the reserved EC2 instances amongst multiple AWS accounts.\n<strong>Use AWS Cost Explorer to manage AWS accounts of all units and then share the reserved EC2 instances amongst all units</strong> - AWS Cost Explorer lets you explore your AWS costs and usage at both a high level and at a detailed level of analysis, and empowering you to dive deeper using several filtering dimensions (e.\ng.\n, AWS Service, Region, Linked Account).\n You cannot use Cost Explorer to share the reserved EC2 instances amongst multiple AWS accounts.\n<strong>Use AWS Systems Manager to manage AWS accounts of all units and then share the reserved EC2 instances amongst all units</strong> - Systems Manager provides a unified user interface so you can view operational data from multiple AWS services and allows you to automate operational tasks across your AWS resources.\n With Systems Manager, you can group resources, like Amazon EC2 instances, Amazon S3 buckets, or Amazon RDS instances, by application, view operational data for monitoring and troubleshooting, and take action on your groups of resources.\n You cannot use Systems Manager to share the reserved EC2 instances amongst multiple AWS accounts.\nReferences:",
            "reference": "https://aws.amazon.com/systems-manager/"
        }
    },
    {
        "id": 64,
        "questions": [
            "Which of the following AWS services have data encryption automatically enabled? (Select two)?"
        ],
        "single_choice": false,
        "answers": [
            {
                "answer": "Amazon Redshift",
                "check": false
            },
            {
                "answer": "Amazon Elastic File System (Amazon EFS)",
                "check": false
            },
            {
                "answer": "AWS Storage Gateway",
                "check": true
            },
            {
                "answer": "Amazon Simple Storage Service (Amazon S3)",
                "check": true
            },
            {
                "answer": "Amazon Elastic Block Store (Amazon EBS)",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>Amazon Simple Storage Service (Amazon S3)</strong>All Amazon S3 buckets have encryption configured by default, and objects are automatically encrypted by using server-side encryption with Amazon S3 managed keys (SSE-S3).\n This encryption setting applies to all objects in your Amazon S3 buckets.\n<strong>AWS Storage Gateway</strong>AWS Storage Gateway is a hybrid cloud storage service that gives you on-premises access to virtually unlimited cloud storage.\n All data transferred between the gateway and AWS storage is encrypted using SSL (for all three types of gateways - File, Volume and Tape Gateways).\n",
            "incorrect": "<strong>Amazon Elastic Block Store (Amazon EBS)</strong> - Amazon Elastic Block Store (Amazon EBS) volumes are not encrypted, by default.\n You can configure your AWS account to enforce the encryption of the new EBS volumes and snapshot copies that you create.\n<strong>Amazon Redshift</strong> - Encryption is an optional setting in Amazon Redshift.\n When you enable encryption for a cluster, the data-blocks and system metadata are encrypted for the cluster and its snapshots.\n<strong>Amazon Elastic File System (Amazon EFS)</strong> - Encryption is not a default setting, but an optional configuration for Amazon EFS drives.\n Amazon EFS supports two forms of encryption for file systems, encryption of data in transit and encryption at rest.\nReferences:",
            "reference": "https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucket-encryption.html"
        }
    },
    {
        "id": 65,
        "questions": [
            "A financial services enterprise plans to enable Multi-Factor Authentication (MFA) for its employees. For ease of travel, they prefer not to use any physical devices to implement Multi-Factor Authentication (MFA). Which of the below options is best suited for this use case?"
        ],
        "single_choice": true,
        "answers": [
            {
                "answer": "Hardware Multi-Factor Authentication (MFA) device",
                "check": false
            },
            {
                "answer": "Virtual Multi-Factor Authentication (MFA) device",
                "check": true
            },
            {
                "answer": "Soft Token Multi-Factor Authentication (MFA) device",
                "check": false
            },
            {
                "answer": "U2F security key",
                "check": false
            }
        ],
        "explanation": {
            "correct": "<strong>Virtual Multi-Factor Authentication (MFA) device</strong>A software app that runs on a phone or other device and emulates a physical device.\n The device generates a six-digit numeric code based upon a time-synchronized one-time password algorithm.\n The user must type a valid code from the device on a second webpage during sign-in.\n Each virtual Multi-Factor Authentication (MFA) device assigned to a user must be unique.\n A user cannot type a code from another user's virtual Multi-Factor Authentication (MFA) device to authenticate.\n",
            "incorrect": "<strong>U2F security key</strong> - A device that you plug into a USB port on your computer.\n U2F is an open authentication standard hosted by the FIDO Alliance.\n When you enable a U2F security key, you sign in by entering your credentials and then tapping the device instead of manually entering a code.\n<strong>Hardware Multi-Factor Authentication (MFA) device</strong> - A hardware device that generates a six-digit numeric code based upon a time-synchronized one-time password algorithm.\n The user must type a valid code from the device on a second webpage during sign-in.\n Each Multi-Factor Authentication (MFA) device assigned to a user must be unique.\n A user cannot type a code from another user's device to be authenticated.\n<strong>Soft Token Multi-Factor Authentication (MFA) device</strong> - This is a made-up option and has been added as a distractor.\nReference:",
            "reference": "https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa.html"
        }
    }
]